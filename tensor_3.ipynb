{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression 실습 전 필요 항목들 import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sklearn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. 데이터셋 재구성하기(Train/test set)</br>\n",
    "외부에서 데이터 셋을 가져오는 부분이며, 이번 예제의 경우 워낙 유명한 예제이니</br>\n",
    "인터넷에 pytorch예제를 잘 수행할 수 있도록 어느정도 정제가 되어 있음</br>\n",
    "향후 전처리 방법에 대해 숙지하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data load & convert to numpy\n",
    "\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\" #예제에 사용할 데이터넷\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "data = pd.DataFrame(data, columns= [\"CRIM\", \"ZN\", \"iNDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\"\n",
    "                                     , \"DIS\", \"RAD\", \"TAX\", \"RTRATIO\", \"B\", \"LSTAT\"])\n",
    "target = raw_df.values[1::2, 2]\n",
    "target = pd.DataFrame(target, columns=[\"MEDV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>iNDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>RTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  iNDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   RTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#전처리된 데이터가 잘 전처리 되었는지 확인해보기\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MEDV\n",
       "0  24.0\n",
       "1  21.6\n",
       "2  34.7\n",
       "3  33.4\n",
       "4  36.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506, 1)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13) (102, 13) (404, 1) (102, 1)\n"
     ]
    }
   ],
   "source": [
    "#데이터 전처리 (input, output)가 잘 됬음을 확인했으니 이제 학습을 위한 준비\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#데이터를 나눠주는 작업 수행 -> 학습을 위해 데이터를 분절함\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "#학습용 데이터 / 평가용 데이터를 나누는데 Test_size가 0.2라는 것은 8:2비율로 나누라는 뜻임\n",
    "#random_stat는 데이터 분할 때 좀 섞어서 분할해라? 라는 뜻임\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 스케일링 작업수행\n",
    "#이거는 학습에 사용되는 데이터의 숫자가 어떤건 0....0으로 되있고 어떤건 100~200으로\n",
    "#변하는 수치가 다 제각각인데 이걸 그냥 학습 시키면 숫자가 큰 데이터 값에\n",
    "#의존하는 경향성이 높아짐. 따라서 데이터의 col별로 0~1사이에서만 움직이는 데이터셋으로\n",
    "#전부 스케일을 맞춰준다 보면 된다.\n",
    "#스케일 과정은 표준 정규분포로 만든다 보면 된다.(평균, 분산을 사용함)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler #정규화 과정을 해주는 모듈\n",
    "\n",
    "#데이터 스케일링 작업\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) #정규화 모델의 기준은 학습용 데이터로만 fit함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 고전적 추론기 사용 -> LSE 기반의 선형 회귀 모델</br>\n",
    "이 모델의 구현은 sklearn Linear Regression Model을 활용함</br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.79653465]\n",
      "[[-1.00213533  0.69626862  0.27806485  0.7187384  -2.0223194   3.14523956\n",
      "  -0.17604788 -3.0819076   2.25140666 -1.76701378 -2.03775151  1.12956831\n",
      "  -3.61165842]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LR_model = LinearRegression(fit_intercept=True)\n",
    "LR_model.fit(X_train, Y_train)\n",
    "\n",
    "print(LR_model.intercept_)#모델의 y절편\n",
    "print(LR_model.coef_)#모델의 계수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   MEDV   R-squared:                       0.751\n",
      "Model:                            OLS   Adj. R-squared:                  0.743\n",
      "Method:                 Least Squares   F-statistic:                     90.43\n",
      "Date:                Sun, 28 Apr 2024   Prob (F-statistic):          6.21e-109\n",
      "Time:                        18:23:50   Log-Likelihood:                -1194.3\n",
      "No. Observations:                 404   AIC:                             2417.\n",
      "Df Residuals:                     390   BIC:                             2473.\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         22.7965      0.236     96.774      0.000      22.333      23.260\n",
      "x1            -1.0021      0.308     -3.250      0.001      -1.608      -0.396\n",
      "x2             0.6963      0.370      1.882      0.061      -0.031       1.423\n",
      "x3             0.2781      0.464      0.599      0.549      -0.634       1.190\n",
      "x4             0.7187      0.247      2.914      0.004       0.234       1.204\n",
      "x5            -2.0223      0.498     -4.061      0.000      -3.001      -1.043\n",
      "x6             3.1452      0.329      9.567      0.000       2.499       3.792\n",
      "x7            -0.1760      0.407     -0.432      0.666      -0.977       0.625\n",
      "x8            -3.0819      0.481     -6.408      0.000      -4.027      -2.136\n",
      "x9             2.2514      0.652      3.454      0.001       0.970       3.533\n",
      "x10           -1.7670      0.704     -2.508      0.013      -3.152      -0.382\n",
      "x11           -2.0378      0.321     -6.357      0.000      -2.668      -1.408\n",
      "x12            1.1296      0.271      4.166      0.000       0.596       1.663\n",
      "x13           -3.6117      0.395     -9.133      0.000      -4.389      -2.834\n",
      "==============================================================================\n",
      "Omnibus:                      133.052   Durbin-Watson:                   2.114\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              579.817\n",
      "Skew:                           1.379   Prob(JB):                    1.24e-126\n",
      "Kurtosis:                       8.181   Cond. No.                         9.74\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#위 LSE모델 해석\n",
    "import statsmodels.api as sm #LR모델은 해석이 가능한데 그걸 해주는 모듈\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train) #y절편을 추가해주겠다는 뜻\n",
    "\n",
    "LR_model_sm = sm.OLS(Y_train, X_train_sm).fit() #LSE(OLS)모델로 fit하겟다는 뜻\n",
    "\n",
    "print(LR_model_sm.summary()) #분석한 모델에 대한 결과값 출력\n",
    "#아래 결과값은 y = ax + b라는 선형추세선이 나왔을 때\n",
    "#그 추세선에 대한 설명이 담긴 문구라 보면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. torch를 활용한 딥러닝(Linear Layer)을 구현해보기</br>\n",
    "정확히는 Fully Connected Layer(Linear Layer)을 모델링한다 보면 된다</br>\n",
    "이거는 FC Layer을 이용한 회귀 모델 구현 이렇게 표현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#바닐라 훈련 버전 만들기 (순정 버전 만들기라 보면 된다..)\n",
    "#처음 명세서에서 레이어를 2개 만들며, (13,6) -> ReLU -> (6,1)이렇게 지나가게 만든다 정의함\n",
    "\n",
    "class MyRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = input_size // 2 #13을 나누기 하고 버리면 6이 나오니까\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=input_size, out_features=self.hidden_size)\n",
    "        self.fc2 = nn.Linear(in_features=self.hidden_size, out_features=1)\n",
    "        #fc1 레이어는 (13, 6), fc2레이어는 (6,1)을 갖게됨\n",
    "\n",
    "    \n",
    "    def forward(self, x): #레이어1 -> Relu -> 레이어2\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "############모델 설계 끝###############\n",
    "\n",
    "ex_model = MyRegressionModel(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss Function 어떤 거 쓸지 정의하기, 최적화 방법론 어떤거 쓸지 정의하기\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(ex_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#앞에서 raw data를 최초로 정제한 데이터를 텐서 자료형으로 전처리 하기\n",
    "import torch.utils\n",
    "\n",
    "\n",
    "data_tensor = torch.tensor(np.array(data), dtype=torch.float32)\n",
    "target_tensor = torch.tensor(np.array(target), dtype=torch.float32)\n",
    "#맨 위에서 불러온 raw data를 텐서 자료형으로 만듬\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(data_tensor, target_tensor)\n",
    "\n",
    "#앞에 LSE 모델용 데이터 셋처럼 훈련/평가용 데이터셋 나누기(과정 같음)\n",
    "test_size = 0.2\n",
    "test_size = int(np.round(test_size * len(dataset)))\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, \n",
    "                                                            [len(dataset)-test_size, test_size])\n",
    "\n",
    "#LSE모델에 사용한 데이터셋이랑 똑같게 훈련/평가용 데이터는 8:2로 나누고 셔플도 하지만\n",
    "#딥러닝 할때는 텐서 자료형만 받으니 자료형만 다르다 보면 된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:43<00:00,  2.27it/s]\n"
     ]
    }
   ],
   "source": [
    "#훈련 과정 함수 만들기(100번 훈련함)\n",
    "\n",
    "for epoch in tqdm(range(100)):\n",
    "    for(x, y) in train_dataset:\n",
    "        #Forward 과정 -> 전사 과정\n",
    "        y_pred = ex_model(x) #레이어를 통과하니 예측값 Y^hat가 나옴\n",
    "\n",
    "        #평가 과정(loss function으로 관측값 측정값 차이 얼마나는지)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        #Backward 과정 -> 평가 결과를 다시 레이어의 Weight matrix에 업데이트\n",
    "        #여기는 백워드 과정에서 옵티마이저 초기화 부분이라 보면 된다.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        #Weight matirx에 업데이트는 여기서 이뤄짐\n",
    "        #Weight matirx의 원소값들은 model parameter이라 부른다\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 학습과정은 CPU만 쓴거라 대용량 모델이 아님</br>\n",
    "대용량 모델을 학습하기 위해 Batch Training 버전을 만들자\n",
    "\n",
    "## Batch Training Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:41<00:00,  2.39it/s]\n"
     ]
    }
   ],
   "source": [
    "#batch training은 그냥 dataloader 모듈 불러오면 끝임\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#batch size 결정하는 부분\n",
    "batch_size = 10\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#배치 사이즈 10으로 정의하고 훈련(위에거랑 코드는 같음)\n",
    "#배치사이즈를 10으로 정의하면 위에꺼 훈련은 한개씩만 데이터 훈련할거 여기서는 10개씩 쓴다는거임\n",
    "#이게 병렬처리임(위에꺼는 병렬처리 아님...) 그래서 속도가 빨라질 거임 -> 근데 CPU라 안빠름 ㅋㅋ;;;\n",
    "\n",
    "for epoch in tqdm(range(100)):\n",
    "    for(x, y) in train_dataset:\n",
    "        y_pred = ex_model(x) #Forward 과정 -> 전사 과정\n",
    "        loss = loss_fn(y_pred, y) #평가 과정\n",
    "\n",
    "        optimizer.zero_grad() #backward - 초기화\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step() #backward - 모델 파라미터 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 CPU 순정학습(한개씩 데이터 훈련) </br>\n",
    "CPU 버전 병렬처리(batch training) 을 했으니 </br>\n",
    "GPU를 사용한 병럴처리를 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:09<00:00,  1.44it/s]\n"
     ]
    }
   ],
   "source": [
    "#GPU사용 가능 확인하기\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "#모델을 GPU로 이동\n",
    "ex_model.to(device)\n",
    "\n",
    "# 옵티마이저에 연결된 파라미터를 GPU로 이동\n",
    "# for param in ex_model.parameters():\n",
    "#     param.to(device)\n",
    "\n",
    "# 훈련 및 평가 데이터셋을 생성한 후에 GPU로 이동\n",
    "train_dataset = torch.utils.data.TensorDataset(data_tensor[:len(dataset)-test_size].to(device), \n",
    "                                               target_tensor[:len(dataset)-test_size].to(device))\n",
    "test_dataset = torch.utils.data.TensorDataset(data_tensor[-test_size:].to(device), \n",
    "                                              target_tensor[-test_size:].to(device))\n",
    "\n",
    "#여기서부터는 위 배치사이즈 설정한거랑 똑같은 코드\n",
    "batch_size = 10\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in tqdm(range(100)):\n",
    "    for(x, y) in train_dataset:\n",
    "        y_pred = ex_model(x.to(device)) #Forward 과정 -> 전사 과정\n",
    "        loss = loss_fn(y_pred, y.to(device)) #평가 과정\n",
    "\n",
    "        optimizer.zero_grad() #backward - 초기화\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step() #backward - 모델 파라미터 업데이트"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
