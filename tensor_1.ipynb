{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor -> n차원의 행렬 형태로 표현되는 데이터(자료형??)</br>\n",
    "(스칼라 텐서 : 0차원, 벡터 텐서 : 1차원 텐서, 매트릭스 텐서 : 2차원 텐서)</br>\n",
    "(여기서 n차원 = n Rank로 표현한다.)</br>\n",
    "ex) 가로 세로 100px인 컬러 사진 이미지 1장은? : [3, 100, 100]의 3차원 텐서 자료형이 될 수 있다.</br>\n",
    "이때, 이 사진 개수가 5장이다 -> [5, 3, 100, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 텐서 자료형 만들기 -> torch.tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13, 45],\n",
       "        [ 2,  3]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(5) #스칼라 텐서 5를 만듬\n",
    "\n",
    "torch.tensor([1, 2, 4, 5, 6]) #1차원 텐서 (벡터)\n",
    "\n",
    "torch.tensor([[13, 45], [2, 3]]) #2차원 텐서 (메트릭스)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5], dtype=torch.int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_list = [1, 2, 3, 4, 5]\n",
    "torch.tensor(tmp_list) #매개변수로 리스트 입력 가능\n",
    "#텐서 자료형에 입력 가능한 매개변수 자료형 : list, set, numpy array\n",
    "\n",
    "torch_set = (1, 2, 3, 4,5)\n",
    "torch.tensor(torch_set)\n",
    "\n",
    "torch_np_array = np.array(tmp_list)\n",
    "torch.tensor(torch_np_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "#torch.ones()  -> element가 1인 tensor을 만들어주는 명령어\n",
    "\n",
    "a = torch.ones([3, 3]) #3 x 3매트릭스 tensor을 만들어달라(이때 각 요소값은 1)\n",
    "\n",
    "b = torch.ones([3,3,3])\n",
    "\n",
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.zeros()는 ones()랑 똑같은데 채우는 요소값이 0인거\n",
    "\n",
    "torch.zeros([4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.arange()는 start, end, step 3가지 매개변수 갖으며, list range랑 같다 보면됨\n",
    "\n",
    "torch.arange(1, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2805, 0.8273, 0.0197],\n",
       "        [0.5078, 0.5821, 0.4135]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.rand()는 0~1사이의 난수 요소를 생성해서 차원값에 맞게 생성\n",
    "\n",
    "torch.rand([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]]) tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]])\n",
      "tensor([[0.8803, 0.6726, 0.6485],\n",
      "        [0.1577, 0.7233, 0.2820]]) tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#torch.xxx_likes() -> 이전에 생성한 텐서와 같은 모양의 tensor 자료형을 만드는데\n",
    "#이 생성된 tensor자료형의 원소값(element)는 xxx에 맞게 채움\n",
    "#xxx는 once, zeros 두개가 있는 듯\n",
    "\n",
    "a = torch.zeros([3,4,5])\n",
    "c = torch.ones_like(a)\n",
    "\n",
    "b = torch.rand([2,3])\n",
    "d = torch.zeros_like(b)\n",
    "\n",
    "print(a, c)\n",
    "print(b, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Attribute : Shape, dtype, device</br>\n",
    "이거는 텐서의 모양, 데이터타입, GPU/CPU로 연산중인지 확인하는거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "torch.Size([3, 4, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3,4,5])\n",
    "print(a.shape)\n",
    "\n",
    "b = torch.ones([3,4,5,5])\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64 torch.float32\n"
     ]
    }
   ],
   "source": [
    "#Tensor.dtype는 텐서의 타입을 보여줌(int, float, double인지)\n",
    "print(a.dtype, b.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 타입을 다른 형식으로 만드는 방법\n",
    "#long, int, double, float를 주로 사용함\n",
    "\n",
    "float_tensor = torch.ones(1, dtype=torch.float)\n",
    "double_tensor = torch.ones(1, dtype=torch.double)\n",
    "complex_float_tensor = torch.ones(1, dtype=torch.complex64)\n",
    "complex_double_tensor = torch.ones(1, dtype=torch.complex128)\n",
    "int_tensor = torch.ones(1, dtype=torch.int)\n",
    "long_tensor = torch.ones(1, dtype=torch.long)\n",
    "uint_tensor = torch.ones(1, dtype=torch.uint8)\n",
    "bool_tensor = torch.ones(1, dtype=torch.bool)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#tensor.device는 쿠다인지 CPU인지 확인하는거\n",
    "\n",
    "a = torch.tensor([1,2,3,4,5])\n",
    "print(a. device)\n",
    "\n",
    "#GPU사용 가능 환경인지 확인하자\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "\n",
    "#사용환경이 available이 된다음 GPU사용환경을 확인하자.\n",
    "torch.cuda.get_device_name(device=0)\n",
    "\n",
    "torch.cuda.device_count()\n",
    "\n",
    "\n",
    "#이거는 텐서 자료형을 GPU에 할당하는 방법\n",
    "a_cuda = torch.tensor([1,23,4,5]).cuda()\n",
    "b_cuda = torch.tensor([1,2,3,4,5]).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvcc'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n"
     ]
    }
   ],
   "source": [
    "! nvcc --V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Tensor Aggregation : Element-wise 연산 -> min, max, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]]) tensor([[5, 6],\n",
      "        [7, 8]])\n",
      "tensor([[ 6,  8],\n",
      "        [10, 12]]) tensor([[-4, -4],\n",
      "        [-4, -4]]) tensor([[ 5, 12],\n",
      "        [21, 32]]) tensor([[0.2000, 0.3333],\n",
      "        [0.4286, 0.5000]])\n",
      "tensor([[ 6,  8],\n",
      "        [10, 12]]) tensor([[-4, -4],\n",
      "        [-4, -4]]) tensor([[ 5, 12],\n",
      "        [21, 32]]) tensor([[0.2000, 0.3333],\n",
      "        [0.4286, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "#element-wise -> 탠서 자료형이 따지고 보면 행렬이니 행렬연산\n",
    "\n",
    "a = torch.tensor([[1,2],[3,4]])\n",
    "b = torch.tensor([[5,6],[7,8]])\n",
    "\n",
    "print(a, b)\n",
    "\n",
    "print(a+b, a-b, a*b,a/b)\n",
    "#이렇게 산술연산으로 행렬 연산이 가능하다.\n",
    "\n",
    "print(a.add(b), a.sub(b), a.mul(b), a.div(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 14],\n",
      "        [17, 20]])\n",
      "tensor([[ 6,  8],\n",
      "        [10, 12]])\n",
      "tensor([[11, 14],\n",
      "        [17, 20]])\n",
      "tensor([[11, 14],\n",
      "        [17, 20]])\n"
     ]
    }
   ],
   "source": [
    "#inplace 연산 -> 연산결과를 반환하면서 자기 자신의 데이터를 고침\n",
    "#연산자 함수 뒤에 '_'를 붙인다\n",
    "#res = a+b인데 _를 붙이면 a = a+b 이게 되버린다는 뜻...\n",
    "\n",
    "print(a.add(b))\n",
    "print(a)\n",
    "\n",
    "print(a.add_(b))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "torch.Size([2, 2])\n",
      "tensor(1)\n",
      "torch.return_types.min(\n",
      "values=tensor([1, 2]),\n",
      "indices=tensor([0, 0]))\n",
      "torch.return_types.min(\n",
      "values=tensor([1, 3]),\n",
      "indices=tensor([0, 0]))\n"
     ]
    }
   ],
   "source": [
    "#Tensor.min() -> 텐서 자료형의 각 원소 값 중 가장 작은 값, 위치 반환\n",
    "\n",
    "a = torch.tensor([[1,2],[3,4]])\n",
    "print(a)\n",
    "\n",
    "print(a.shape)\n",
    "print(a.min())\n",
    "print(a.min(dim=0))\n",
    "print(a.min(dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3., 4.],\n",
      "        [2., 4., 5.]])\n",
      "torch.Size([2, 3])\n",
      "tensor(5.)\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 4., 5.]),\n",
      "indices=tensor([0, 1, 1]))\n",
      "torch.return_types.max(\n",
      "values=tensor([4., 5.]),\n",
      "indices=tensor([2, 2]))\n"
     ]
    }
   ],
   "source": [
    "#tensor.max() 이거는 가장 큰 값을 반환해줌\n",
    "\n",
    "b = torch.tensor([[2,3,4],[2,4,5]])\n",
    "\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(b.max())\n",
    "\n",
    "print(b.max(dim=0))\n",
    "print(b.max(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3., 4.],\n",
      "        [2., 4., 5.]])\n",
      "tensor(3.3333)\n",
      "tensor([2.0000, 3.5000, 4.5000])\n",
      "tensor([3.0000, 3.6667])\n"
     ]
    }
   ],
   "source": [
    "# tensor.mean() -> 요소의 전체 평균 혹은 argument에 지정한 차원의 내 요소의 전제평균\n",
    "\n",
    "b = torch.tensor([[2,3,4],[2,4,5]], dtype=torch.float)\n",
    "\n",
    "print(b)\n",
    "\n",
    "print(b.mean())\n",
    "\n",
    "print(b.mean(dim=0))\n",
    "print(b.mean(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Index -> numpy, pandas의 인덱싱과 유사함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "tensor([4, 5, 6])\n",
      "tensor(6)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "\n",
    "print(a.shape)\n",
    "\n",
    "print(a[1])\n",
    "\n",
    "print(a[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3612, 0.1982, 0.6672],\n",
      "         [0.8384, 0.3059, 0.8934],\n",
      "         [0.0416, 0.7388, 0.5850]],\n",
      "\n",
      "        [[0.7501, 0.0291, 0.5800],\n",
      "         [0.8967, 0.9097, 0.8916],\n",
      "         [0.8819, 0.1856, 0.7407]],\n",
      "\n",
      "        [[0.5438, 0.6362, 0.4709],\n",
      "         [0.7654, 0.1145, 0.3741],\n",
      "         [0.5163, 0.7952, 0.1378]]])\n",
      "tensor([[[0.3612, 0.1982, 0.6672],\n",
      "         [0.8384, 0.3059, 0.8934],\n",
      "         [0.0416, 0.7388, 0.5850]],\n",
      "\n",
      "        [[0.7501, 0.0291, 0.5800],\n",
      "         [0.8967, 0.9097, 0.8916],\n",
      "         [0.8819, 0.1856, 0.7407]]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.rand([3,3,3])\n",
    "print(b)\n",
    "print(b[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Shaping Opeation : reshape, squeeze/unsqueeze, stack, cat </br>\n",
    "텐서 자료형의 차원이나 모양을 바꾸는것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n",
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n",
      "tensor([[[1, 2, 3, 4],\n",
      "         [5, 6, 7, 8]]])\n",
      "tensor([[1, 2, 3, 4, 5, 6, 7, 8]])\n",
      "torch.Size([1, 8])\n"
     ]
    }
   ],
   "source": [
    "#tensor.reshape() -> 모양 변경(차원의 길이 변경)\n",
    "#만약 차원의 모든 곱 값이 x * y * z = k 일 때\n",
    "#이 k를 만들 수 있는 다른 공약수로 reshape가 가능하다.\n",
    "\n",
    "a = torch.tensor([[1,2,3,4],[5,6,7,8]])\n",
    "\n",
    "print(a.shape)\n",
    "\n",
    "print(a.reshape([4,2]))\n",
    "\n",
    "print(a.reshape([2,2,2]))\n",
    "\n",
    "print(a.reshape([1,2,4]))\n",
    "\n",
    "print(a.reshape([-1, 8]))\n",
    "print(a.reshape([-1, 8]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1961, 0.0294, 0.6034]],\n",
      "\n",
      "        [[0.4980, 0.8593, 0.3893]],\n",
      "\n",
      "        [[0.2112, 0.2826, 0.9144]]])\n",
      "torch.Size([3, 1, 3])\n",
      "tensor([[0.1961, 0.0294, 0.6034],\n",
      "        [0.4980, 0.8593, 0.3893],\n",
      "        [0.2112, 0.2826, 0.9144]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "#Tensor.squeeze() -> 차원의 값이 1인 차원을 제거한다\n",
    "#차원의 값이 1인건 따지고 보면 원소가 없이 []이것만 붙은거니까 없애준다는 거임\n",
    "#차원이 꽤 높은 고차원 tensor자료형을 정사영 한다는 뜻이 된다 보면 됨\n",
    "\n",
    "a = torch.rand([3,1,3])\n",
    "\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.squeeze())\n",
    "print(a.squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensor.unsqueeze() 이거는 반대로 차원을 늘리는것\n",
    "#Tensor.squeeze()와 같게 argument로 dim을 쓸 수 있는데 이거로\n",
    "#늘리거나 줄이는 차원을 조정할 수 있음\n",
    "\n",
    "b = torch.tensor([[1,2,3,4],[5,6,7,8],[9,10,11,12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 24, 50])\n",
      "torch.Size([5, 48, 50])\n",
      "torch.Size([5, 24, 100])\n",
      "torch.Size([10, 24, 50])\n",
      "\n",
      "torch.Size([2, 5, 24, 50])\n",
      "torch.Size([5, 2, 24, 50])\n",
      "torch.Size([5, 24, 2, 50])\n",
      "\n",
      "torch.Size([2, 3, 4])\n",
      "torch.Size([3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "#torch.cat(), torch.stack() -> 두개의 tensor자료형을 합치는 방식\n",
    "\n",
    "a = torch.rand(5, 24, 50) #M, N, K\n",
    "b = torch.rand(5, 24, 50) #M, N, K\n",
    "\n",
    "res1 = torch.cat([a,b], dim = 0) # -> 이거는 첫번재 차원값 M을 M+M, N, K하는거\n",
    "\n",
    "res2 = torch.cat([a,b], dim=1) # 이거는 N값을 N+N\n",
    "res3 = torch.cat([a,b], dim=2) \n",
    "\n",
    "print(res1.shape)\n",
    "print(res2.shape)\n",
    "print(res3.shape)\n",
    "\n",
    "\n",
    "c = torch.rand(5,24,50)\n",
    "d = torch.rand(2,24,50)\n",
    "#위 경우에는 cat할 시 dim=0만 가능하다 -> 이유는 M+M 일때 N, K는 같은 값이어야함\n",
    "#N+N하려면, M, K가 각각 같은 값이어야 하는데 M이 다름\n",
    "\n",
    "res_1 = torch.cat([a,b], dim=0)\n",
    "print(res_1.shape)\n",
    "\n",
    "\n",
    "e = torch.rand(3, 24, 50)\n",
    "f = torch.rand(3, 24, 50)\n",
    "\n",
    "res_1_1 = torch.stack([a, b], dim=0)\n",
    "res_1_2 = torch.stack([a, b], dim=1)\n",
    "res_1_3 = torch.stack([a, b], dim=2)\n",
    "\n",
    "print()\n",
    "print(res_1_1.shape)\n",
    "print(res_1_2.shape)\n",
    "print(res_1_3.shape)\n",
    "\n",
    "\n",
    "aa = torch.rand(3, 4)\n",
    "bb = torch.rand(3, 4)\n",
    "\n",
    "res_2_1 = torch.stack([aa,bb], dim=0)\n",
    "res_2_2 = torch.stack([aa,bb], dim=1)\n",
    "\n",
    "print()\n",
    "print(res_2_1.shape)\n",
    "print(res_2_2.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
