{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. CNN학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision #예제 이미지 데이터셋이 모여있는 모듈\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rand 함수를 쓰는데 seed를 고정해서 쓴다. -> 평가 시 변인통제를 위해\n",
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSHEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "#강의랑 똑같은 결과를 내라고 랜덤값 고정하는데 하지말자...\n",
    "#seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.0280,  0.0392, -0.1059],\n",
      "          [-0.0659, -0.0331, -0.0181],\n",
      "          [-0.0187, -0.1907,  0.1569]],\n",
      "\n",
      "         [[ 0.1831,  0.1193, -0.1420],\n",
      "          [ 0.0094, -0.0953, -0.0069],\n",
      "          [-0.0298, -0.1232, -0.1739]],\n",
      "\n",
      "         [[ 0.0973,  0.1780,  0.1132],\n",
      "          [ 0.1321, -0.1460, -0.0755],\n",
      "          [-0.0322,  0.1486,  0.0478]]],\n",
      "\n",
      "\n",
      "        [[[-0.0800,  0.0025,  0.0167],\n",
      "          [ 0.0921, -0.1618,  0.1182],\n",
      "          [-0.0650, -0.0144, -0.0281]],\n",
      "\n",
      "         [[ 0.1338,  0.1634, -0.0177],\n",
      "          [-0.0260, -0.0130,  0.1669],\n",
      "          [ 0.0511, -0.0106,  0.1660]],\n",
      "\n",
      "         [[ 0.1558, -0.1395, -0.0070],\n",
      "          [-0.0973,  0.0927,  0.1091],\n",
      "          [ 0.0555,  0.0011,  0.1365]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0401, -0.0243], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#conv 레이어 정의하기\n",
    "conv = nn.Conv2d(in_channels=3, out_channels=2, kernel_size=3, stride=1, padding='same')\n",
    "\n",
    "for p in conv.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "#input 텐서 정의하기\n",
    "input = torch.randn(10, 3, 7, 7) #배치사이즈, input_dim, (세로 가로)-> 이미지 크기\n",
    "\n",
    "#정의한 input텐서에 conv를 통과시켜 보기\n",
    "output = conv(input)\n",
    "\n",
    "print(output.shape)\n",
    "#여기까지가 진짜 간단히 알아본 conv 작동예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CNN 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터셋 받아오고 전처리 수행하기\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader( #여기서 train=True는 훈련용 데이터 받아라\n",
    "    datasets.FashionMNIST(\"data\", train=True, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(), #download=True는 파일이 없으면 다운받아라\n",
    "        transforms.Normalize((0.1307, ), (0.3081, )) #transform는 이미지 전처리의 방법론\n",
    "    ])), #Normalize는 정규분포로 스케일링 작업 (평균, 분산)\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader( #여기서 train=False는 평가용 데이터 받아라\n",
    "    datasets.FashionMNIST(\"data\", train=False, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307, ), (0.3081, ))\n",
    "    ])),\n",
    "    batch_size=64, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN 모델 설계하기\n",
    "\n",
    "class Fashion_MNIST_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Fashion_MNIST_Model, self).__init__()\n",
    "\n",
    "        #conv1의 input_dim이 1인 이유 : Fashion_MNIST_Model의 데이터셋은 '그레이스케일'이다.\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3) #input_dim이 1, output_dim은 32\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3) #길쭉한 정육면체로 만드는 과정\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = F.max_pool2d(x, 2) #바로 위 레이어를 반으로 줄임\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = x.view(-1, 64 * 5 * 5) #Flatten과정 -> \n",
    "        #64는 conv2를 통과하고 나온 채널 수, 5x5는 conv2를 통과하고 나온 feature map사이즈\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "CNN_ex_model = Fashion_MNIST_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#로스함수, 옵티마이저 선언\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(CNN_ex_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/5], step : [100/938], Loss : 0.0407\n",
      "Epoch : [1/5], step : [200/938], Loss : 0.1118\n",
      "Epoch : [1/5], step : [300/938], Loss : 0.2418\n",
      "Epoch : [1/5], step : [400/938], Loss : 0.1467\n",
      "Epoch : [1/5], step : [500/938], Loss : 0.1138\n",
      "Epoch : [1/5], step : [600/938], Loss : 0.2056\n",
      "Epoch : [1/5], step : [700/938], Loss : 0.1511\n",
      "Epoch : [1/5], step : [800/938], Loss : 0.1053\n",
      "Epoch : [1/5], step : [900/938], Loss : 0.2325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:04<04:18, 64.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/5], step : [100/938], Loss : 0.1791\n",
      "Epoch : [2/5], step : [200/938], Loss : 0.0800\n",
      "Epoch : [2/5], step : [300/938], Loss : 0.2170\n",
      "Epoch : [2/5], step : [400/938], Loss : 0.1608\n",
      "Epoch : [2/5], step : [500/938], Loss : 0.0785\n",
      "Epoch : [2/5], step : [600/938], Loss : 0.2059\n",
      "Epoch : [2/5], step : [700/938], Loss : 0.1331\n",
      "Epoch : [2/5], step : [800/938], Loss : 0.1057\n",
      "Epoch : [2/5], step : [900/938], Loss : 0.1782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [02:02<03:01, 60.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/5], step : [100/938], Loss : 0.1472\n",
      "Epoch : [3/5], step : [200/938], Loss : 0.0924\n",
      "Epoch : [3/5], step : [300/938], Loss : 0.0966\n",
      "Epoch : [3/5], step : [400/938], Loss : 0.1718\n",
      "Epoch : [3/5], step : [500/938], Loss : 0.1102\n",
      "Epoch : [3/5], step : [600/938], Loss : 0.0995\n",
      "Epoch : [3/5], step : [700/938], Loss : 0.1393\n",
      "Epoch : [3/5], step : [800/938], Loss : 0.1010\n",
      "Epoch : [3/5], step : [900/938], Loss : 0.0804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [03:00<01:58, 59.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/5], step : [100/938], Loss : 0.1557\n",
      "Epoch : [4/5], step : [200/938], Loss : 0.1078\n",
      "Epoch : [4/5], step : [300/938], Loss : 0.1509\n",
      "Epoch : [4/5], step : [400/938], Loss : 0.1641\n",
      "Epoch : [4/5], step : [500/938], Loss : 0.1545\n",
      "Epoch : [4/5], step : [600/938], Loss : 0.0585\n",
      "Epoch : [4/5], step : [700/938], Loss : 0.0828\n",
      "Epoch : [4/5], step : [800/938], Loss : 0.1677\n",
      "Epoch : [4/5], step : [900/938], Loss : 0.1492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [03:57<00:58, 58.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/5], step : [100/938], Loss : 0.0894\n",
      "Epoch : [5/5], step : [200/938], Loss : 0.1592\n",
      "Epoch : [5/5], step : [300/938], Loss : 0.1274\n",
      "Epoch : [5/5], step : [400/938], Loss : 0.0444\n",
      "Epoch : [5/5], step : [500/938], Loss : 0.0704\n",
      "Epoch : [5/5], step : [600/938], Loss : 0.1202\n",
      "Epoch : [5/5], step : [700/938], Loss : 0.1110\n",
      "Epoch : [5/5], step : [800/938], Loss : 0.0820\n",
      "Epoch : [5/5], step : [900/938], Loss : 0.0560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [04:55<00:00, 59.14s/it]\n"
     ]
    }
   ],
   "source": [
    "#훈련 시작!\n",
    "\n",
    "CNN_ex_model.train()\n",
    "\n",
    "for epoch in tqdm(range(5)): #CPU에서 훈련시키는거라 속도가 엄청오래걸리니 5개만 함..\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.view(-1, 1, 28, 28)#이미지의 채널, 사이즈(y, x)\n",
    "        labels = labels\n",
    "\n",
    "        #여기가 forward\n",
    "        outputs = CNN_ex_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad() #옵티마이저 초기화\n",
    "\n",
    "        #여기가 backward\n",
    "        loss.backward()\n",
    "        optimizer.step() #모델 파라미터 업데이트\n",
    "\n",
    "\n",
    "        #여기는 중간중간 확인과정\n",
    "        if (i+1) % 100 == 0: #100스탭당 한번씩 프린트하기\n",
    "            print('Epoch : [{}/{}], step : [{}/{}], Loss : {:.4f}'.format(\n",
    "                epoch+1, 5, i+1, len(train_loader), loss.item()\n",
    "            ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU에서 구동시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Fashion_MNIST_Model(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=1600, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#GPU사용 가능 확인하기\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "#학습 모델 GPU로 이전하기\n",
    "print(CNN_ex_model.to(device))\n",
    "\n",
    "print(next(CNN_ex_model.parameters()).device) #모델 파라미터의 위치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#로스 함수랑 옵티아이저 재 선언해서 GPU로 이전하기\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(CNN_ex_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [01:59<18:46, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10/5], step : [100/938], Loss : 0.0138\n",
      "Epoch : [10/5], step : [200/938], Loss : 0.0153\n",
      "Epoch : [10/5], step : [300/938], Loss : 0.0394\n",
      "Epoch : [10/5], step : [400/938], Loss : 0.0370\n",
      "Epoch : [10/5], step : [500/938], Loss : 0.0857\n",
      "Epoch : [10/5], step : [600/938], Loss : 0.0038\n",
      "Epoch : [10/5], step : [700/938], Loss : 0.0930\n",
      "Epoch : [10/5], step : [800/938], Loss : 0.0656\n",
      "Epoch : [10/5], step : [900/938], Loss : 0.0406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [04:00<16:26, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [20/5], step : [100/938], Loss : 0.0153\n",
      "Epoch : [20/5], step : [200/938], Loss : 0.0258\n",
      "Epoch : [20/5], step : [300/938], Loss : 0.0097\n",
      "Epoch : [20/5], step : [400/938], Loss : 0.0190\n",
      "Epoch : [20/5], step : [500/938], Loss : 0.0197\n",
      "Epoch : [20/5], step : [600/938], Loss : 0.0152\n",
      "Epoch : [20/5], step : [700/938], Loss : 0.0117\n",
      "Epoch : [20/5], step : [800/938], Loss : 0.0020\n",
      "Epoch : [20/5], step : [900/938], Loss : 0.1258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [06:02<14:24, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [30/5], step : [100/938], Loss : 0.0048\n",
      "Epoch : [30/5], step : [200/938], Loss : 0.0023\n",
      "Epoch : [30/5], step : [300/938], Loss : 0.0056\n",
      "Epoch : [30/5], step : [400/938], Loss : 0.0042\n",
      "Epoch : [30/5], step : [500/938], Loss : 0.0293\n",
      "Epoch : [30/5], step : [600/938], Loss : 0.0013\n",
      "Epoch : [30/5], step : [700/938], Loss : 0.0111\n",
      "Epoch : [30/5], step : [800/938], Loss : 0.0836\n",
      "Epoch : [30/5], step : [900/938], Loss : 0.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [08:05<12:32, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [40/5], step : [100/938], Loss : 0.0031\n",
      "Epoch : [40/5], step : [200/938], Loss : 0.0045\n",
      "Epoch : [40/5], step : [300/938], Loss : 0.0002\n",
      "Epoch : [40/5], step : [400/938], Loss : 0.0048\n",
      "Epoch : [40/5], step : [500/938], Loss : 0.0005\n",
      "Epoch : [40/5], step : [600/938], Loss : 0.0231\n",
      "Epoch : [40/5], step : [700/938], Loss : 0.0099\n",
      "Epoch : [40/5], step : [800/938], Loss : 0.0001\n",
      "Epoch : [40/5], step : [900/938], Loss : 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [10:16<11:03, 13.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [50/5], step : [100/938], Loss : 0.0017\n",
      "Epoch : [50/5], step : [200/938], Loss : 0.0014\n",
      "Epoch : [50/5], step : [300/938], Loss : 0.0004\n",
      "Epoch : [50/5], step : [400/938], Loss : 0.1629\n",
      "Epoch : [50/5], step : [500/938], Loss : 0.0017\n",
      "Epoch : [50/5], step : [600/938], Loss : 0.0613\n",
      "Epoch : [50/5], step : [700/938], Loss : 0.0152\n",
      "Epoch : [50/5], step : [800/938], Loss : 0.0003\n",
      "Epoch : [50/5], step : [900/938], Loss : 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [12:24<08:41, 12.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [60/5], step : [100/938], Loss : 0.0304\n",
      "Epoch : [60/5], step : [200/938], Loss : 0.0004\n",
      "Epoch : [60/5], step : [300/938], Loss : 0.0002\n",
      "Epoch : [60/5], step : [400/938], Loss : 0.0127\n",
      "Epoch : [60/5], step : [500/938], Loss : 0.0001\n",
      "Epoch : [60/5], step : [600/938], Loss : 0.0154\n",
      "Epoch : [60/5], step : [700/938], Loss : 0.0212\n",
      "Epoch : [60/5], step : [800/938], Loss : 0.0033\n",
      "Epoch : [60/5], step : [900/938], Loss : 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [14:26<06:18, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [70/5], step : [100/938], Loss : 0.0064\n",
      "Epoch : [70/5], step : [200/938], Loss : 0.0006\n",
      "Epoch : [70/5], step : [300/938], Loss : 0.0005\n",
      "Epoch : [70/5], step : [400/938], Loss : 0.0002\n",
      "Epoch : [70/5], step : [500/938], Loss : 0.0064\n",
      "Epoch : [70/5], step : [600/938], Loss : 0.0082\n",
      "Epoch : [70/5], step : [700/938], Loss : 0.0004\n",
      "Epoch : [70/5], step : [800/938], Loss : 0.1122\n",
      "Epoch : [70/5], step : [900/938], Loss : 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [16:32<04:33, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [80/5], step : [100/938], Loss : 0.0001\n",
      "Epoch : [80/5], step : [200/938], Loss : 0.0000\n",
      "Epoch : [80/5], step : [300/938], Loss : 0.0051\n",
      "Epoch : [80/5], step : [400/938], Loss : 0.0016\n",
      "Epoch : [80/5], step : [500/938], Loss : 0.0004\n",
      "Epoch : [80/5], step : [600/938], Loss : 0.0001\n",
      "Epoch : [80/5], step : [700/938], Loss : 0.0255\n",
      "Epoch : [80/5], step : [800/938], Loss : 0.0897\n",
      "Epoch : [80/5], step : [900/938], Loss : 0.1037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [18:42<02:24, 13.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [90/5], step : [100/938], Loss : 0.0000\n",
      "Epoch : [90/5], step : [200/938], Loss : 0.0048\n",
      "Epoch : [90/5], step : [300/938], Loss : 0.0004\n",
      "Epoch : [90/5], step : [400/938], Loss : 0.0000\n",
      "Epoch : [90/5], step : [500/938], Loss : 0.0000\n",
      "Epoch : [90/5], step : [600/938], Loss : 0.0007\n",
      "Epoch : [90/5], step : [700/938], Loss : 0.0000\n",
      "Epoch : [90/5], step : [800/938], Loss : 0.0006\n",
      "Epoch : [90/5], step : [900/938], Loss : 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [20:54<00:13, 13.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [100/5], step : [100/938], Loss : 0.0000\n",
      "Epoch : [100/5], step : [200/938], Loss : 0.0000\n",
      "Epoch : [100/5], step : [300/938], Loss : 0.0000\n",
      "Epoch : [100/5], step : [400/938], Loss : 0.0351\n",
      "Epoch : [100/5], step : [500/938], Loss : 0.0071\n",
      "Epoch : [100/5], step : [600/938], Loss : 0.0000\n",
      "Epoch : [100/5], step : [700/938], Loss : 0.0001\n",
      "Epoch : [100/5], step : [800/938], Loss : 0.0066\n",
      "Epoch : [100/5], step : [900/938], Loss : 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [21:07<00:00, 12.68s/it]\n"
     ]
    }
   ],
   "source": [
    "#훈련 시작(GPU모드에서)\n",
    "\n",
    "for epoch in tqdm(range(100)): #이번엔 GPU에서 훈련시키니 자\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.view(-1, 1, 28, 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #여기가 forward\n",
    "        outputs = CNN_ex_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad() #옵티마이저 초기화\n",
    "\n",
    "        #여기가 backward\n",
    "        loss.backward()\n",
    "        optimizer.step() #모델 파라미터 업데이트\n",
    "\n",
    "\n",
    "        #여기는 중간중간 확인과정\n",
    "        if (epoch+1) % 10 == 0 and (i+1) % 100 == 0: #100스탭당 한번씩 프린트하기\n",
    "            print('Epoch : [{}/{}], step : [{}/{}], Loss : {:.4f}'.format(\n",
    "                epoch+1, 100, i+1, len(train_loader), loss.item()\n",
    "            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습된 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수행 결과 정확도 : 90.96%\n"
     ]
    }
   ],
   "source": [
    "#모델을 평가모드로 전환\n",
    "CNN_ex_model.eval()\n",
    "\n",
    "#평가를 위해 임의의 두 변수를 선언후 GPU로 보냄\n",
    "Y_pred, Y_true = torch.zeros([64]).to(device), torch.zeros([64]).to(device)\n",
    "total, correct = 0, 0\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(-1, 1, 28, 28).to(device) #평가용 이미지를 GPU로 이전\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = CNN_ex_model(images) #softmax를 통과하니 확률로 값이 나옴\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "\n",
    "        if(predicted.shape[0] != 64): #이거는 배치 이미지 부족할 때 동작하는 함수\n",
    "            predicted = torch.cat([predicted, torch.zeros(64-predicted.shape[0]).to(device)])\n",
    "            labels = torch.cat([labels, torch.zeros(64-labels.shape[0]).to(device)])\n",
    "\n",
    "        \n",
    "        Y_pred = torch.cat([Y_pred, predicted])\n",
    "        Y_true = torch.cat([Y_true, labels])\n",
    "\n",
    "        total = total + labels.size(0)\n",
    "        correct = correct + (predicted == labels).sum().item()\n",
    "\n",
    "print(\"수행 결과 정확도 : {:.2f}%\".format((correct/total)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.88      0.86      1112\n",
      "         1.0       0.99      0.98      0.99      1000\n",
      "         2.0       0.85      0.87      0.86      1000\n",
      "         3.0       0.91      0.91      0.91      1000\n",
      "         4.0       0.88      0.85      0.86      1000\n",
      "         5.0       0.98      0.98      0.98      1000\n",
      "         6.0       0.77      0.74      0.75      1000\n",
      "         7.0       0.96      0.96      0.96      1000\n",
      "         8.0       0.98      0.98      0.98      1000\n",
      "         9.0       0.97      0.96      0.97      1000\n",
      "\n",
      "    accuracy                           0.91     10112\n",
      "   macro avg       0.91      0.91      0.91     10112\n",
      "weighted avg       0.91      0.91      0.91     10112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#이제 수행한 결과를 리포트로 출력하는데 CPU로 내려야 한다.\n",
    "Y_true = Y_true.detach().cpu().numpy()\n",
    "Y_pred = Y_pred.detach().cpu().numpy()\n",
    "\n",
    "print(classification_report(Y_true, Y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
