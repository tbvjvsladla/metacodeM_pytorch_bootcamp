{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# 데이터셋 표준화를 위한 기본정보 # 패치(반사패딩 추가해야함)\n",
    "imgNet_val = {'mean' : [0.485, 0.456, 0.406], 'std' : [0.229, 0.224, 0.225]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from img_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_img = './seoul.png'\n",
    "style_img = './starnight.png'\n",
    "\n",
    "content_tensor, img_shape = preprocess_img(content_img, 512, imgNet_val, device)\n",
    "style_tensor, _ = preprocess_img(style_img, 512, imgNet_val, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_img = create_random_noise_img(img_shape)\n",
    "task_img.save(\"random_noise.jpg\")\n",
    "\n",
    "task_tensor, _ = preprocess_img('random_noise.jpg', 512, imgNet_val, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# 항목별로 lossfn 설계\n",
    "class TransferLoss():\n",
    "    def __init__(self, target_feature, item):\n",
    "        item_msg_list = ['content', 'style']\n",
    "        self.item = item #해당 feature이 content인지, style인지 확인\n",
    "        if self.item not in item_msg_list:\n",
    "            raise Exception(\"item 종류 잘못 입력\")\n",
    "\n",
    "        # target_feaute이 딕셔너리 형태이니 value값만 추출해 리스트화\n",
    "        self.target = list(target_feature.values())\n",
    "\n",
    "        # 그람 행렬(Gram matrix) 함수 정의\n",
    "    def gram_matrix(self, data_tensor):\n",
    "        bs, c, h, w = data_tensor.size() #여기서 bs는 1이다.\n",
    "        #Feature Map에서 채널별로 분리 (Features)\n",
    "        #그 다음 이 features는 3차원이니 H*W를 곱해서 2D로 차원축소\n",
    "        features = data_tensor.view(bs*c, h*w)\n",
    "        #모든 Features별로 내적을 땡겨버리자 -> 모든 instance pair값 계산\n",
    "        #torch.mm은 행렬곱 메서드임\n",
    "        G = torch.mm(features, features.t())\n",
    "        #gram matrix의 값을 정규화 수행\n",
    "        return G.div(bs*c*h*w)\n",
    "\n",
    "    def cal_loss(self, input): #입력되는 input도 딕셔너리 형태\n",
    "        input = list(input.values()) #input를 리스트로 형변환\n",
    "        # loss를 0으로 초기화 및 디바이스 위치 지정\n",
    "        device = input[0].device\n",
    "        loss = torch.zeros(1, device=device)\n",
    "\n",
    "        # 콘텐츠 로스는 1개의 output_feature에 대해서 loss계산\n",
    "        if self.item == 'content':\n",
    "            loss += F.mse_loss(input[0], self.target[0])\n",
    "\n",
    "        # 스타일 로스는 여러개의 output_feature를 그람 매트릭스 해서 Loss계산\n",
    "        elif self.item == 'style':\n",
    "            for e_input, e_target in zip(input, self.target):\n",
    "                G_input = self.gram_matrix(e_input)\n",
    "                G_style = self.gram_matrix(e_target)\n",
    "                loss += F.mse_loss(G_input, G_style)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴럴 스타일 트랜스퍼에 사용할 백본 모델 불러오기\n",
    "# torchvision에 있는 VGG19모델을 사용\n",
    "from torchvision import models\n",
    "\n",
    "pr_model = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReModelVGG19(nn.Module):\n",
    "    def __init__(self, origin_model):\n",
    "        super(ReModelVGG19, self).__init__()\n",
    "        origin_modeul = origin_model.features\n",
    "        self.module = nn.ModuleDict()\n",
    "\n",
    "        block = []\n",
    "        block_idx = 0\n",
    "\n",
    "        for layer in origin_modeul.children():\n",
    "            if isinstance(layer, nn.Conv2d) and block: #블럭이 비어있지 않은 경우\n",
    "                # 새로운 conv2d가 나오면 기존 블록을 저장하고 초기화\n",
    "                block_name = f\"conv_{block_idx}_block\"\n",
    "                self.module[block_name] = nn.Sequential(*block)\n",
    "\n",
    "                #블록 리스트 초기화\n",
    "                block = []\n",
    "                block_idx += 1\n",
    "            if isinstance(layer, nn.ReLU):\n",
    "                #in-place기능이 켜져있으면 잘 동작을 안한다고 함\n",
    "                layer = nn.ReLU(inplace=False)\n",
    "            #레이어를 계속 블럭 리스트에 넣기\n",
    "            block.append(layer)\n",
    "\n",
    "        if block: #가장 마지막 블록을 추가\n",
    "            block_name = f\"conv_{block_idx}_block\"\n",
    "            self.module[block_name] = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self.module.values():\n",
    "            x = block(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReModelVGG19(\n",
       "  (module): ModuleDict(\n",
       "    (conv_0_block): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (conv_1_block): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv_2_block): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (conv_3_block): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv_4_block): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (conv_5_block): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (conv_6_block): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (conv_7_block): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv_8_block): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (conv_9_block): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (conv_10_block): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (conv_11_block): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv_12_block): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (conv_13_block): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (conv_14_block): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (conv_15_block): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone = ReModelVGG19(pr_model)\n",
    "#backbone는 평가 모드로 설정\n",
    "backbone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_block = ['conv_3_block']\n",
    "style_block = ['conv_0_block', \n",
    "                'conv_1_block', \n",
    "                'conv_2_block', \n",
    "                'conv_3_block', \n",
    "                'conv_4_block', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralStyleNet(nn.Module):\n",
    "    def __init__(self, backbone, block_setting):\n",
    "        super(NeuralStyleNet, self).__init__()\n",
    "\n",
    "        self.backbone = backbone #백본 모델의 인스턴스화\n",
    "        self.block_setting = block_setting #캡쳐할 output feature리스트 가져오기\n",
    "        self.outputs = {} #캡쳐할 feature out 저장\n",
    "\n",
    "        def hook_fn(module, input, output, name):\n",
    "            #캡쳐한 블럭 이름이 outputs 딕셔너리에 없을 경우\n",
    "            #블럭의 출력feature이랑 block이름을 key,value로 묶어서 outputs에 저장\n",
    "            if name not in self.outputs:\n",
    "                self.outputs[name] = output\n",
    "\n",
    "        for module in self.backbone.children():\n",
    "            for sub_name, sub_module in module.named_modules():\n",
    "                if any(block == sub_name for block in self.block_setting):\n",
    "                    # block_setting에 명기된 블럭의 output_feature만 캡쳐\n",
    "                    self._register_hook(sub_name, sub_module, hook_fn)\n",
    "\n",
    "    def _register_hook(self, name, module, hook_fn):\n",
    "        def hook(module, input, output): #여기서 name = 캡쳐한 모듈(블럭)의 이름\n",
    "            return hook_fn(module, input, output, name)\n",
    "        module.register_forward_hook(hook)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _ = self.backbone(x)\n",
    "        return self.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "class StyleTransfer:\n",
    "    def __init__(self, backbone, content_block, style_block,\n",
    "                 learning_rate = 0.01,\n",
    "                 weight_c = 1, weight_s = 1):\n",
    "        self.backbone = backbone\n",
    "        self.content_block = content_block\n",
    "        self.style_block = style_block\n",
    "\n",
    "        self.weight = [weight_c, weight_s]\n",
    "\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        self.task_model = None\n",
    "\n",
    "    def initalize(self, content, style): #처음 초기화 해야할 항목들\n",
    "        content_model = NeuralStyleNet(self.backbone, self.content_block)\n",
    "        style_model = NeuralStyleNet(self.backbone, self.style_block)\n",
    "\n",
    "        #Target 콘텐츠, 스타일 Feature을 캡쳐함(초기, 단 한번만 수행)\n",
    "        with torch.no_grad(): #평가모드이니 grad계산 중지\n",
    "            target_content = content_model(content)\n",
    "            style_content = style_model(style)\n",
    "        \n",
    "        # 콘텐츠&스타일 Feature기반으로 LossFn을 초기화\n",
    "        self.content_loss_fn = TransferLoss(target_content, 'content')\n",
    "        self.style_loss_fn = TransferLoss(style_content, 'style')\n",
    "\n",
    "        #모델에 작업에 필요한 캡쳐 블록 리스트를 넣고 초기화\n",
    "        #이때 캡쳐할 블럭은 콘텐츠+스타일 블럭 합산\n",
    "        task_block = self.content_block + self.style_block\n",
    "        self.task_model = NeuralStyleNet(backbone, task_block)\n",
    "\n",
    "    def compute_loss(self, pred_task): #작업이미지가 모델을 통과한 결과물로 로스 계산\n",
    "        #콘텐츠 로스, 스타일 로스랑 비교할 블럭들을 추출\n",
    "        pred_content = {k: v for k, v in pred_task.items() if k in self.content_block}\n",
    "        pred_style = {k: v for k, v in pred_task.items() if k in self.style_block}\n",
    "\n",
    "        #추출한 블럭을 바탕으로 콘텐츠로스, 스타일로스 계산\n",
    "        content_loss = self.content_loss_fn.cal_loss(pred_content)\n",
    "        style_loss = self.style_loss_fn.cal_loss(pred_style)\n",
    "\n",
    "        #사전에 정의한 '항목별'가중치를 로스에 곱해서 토탈 로스 정의\n",
    "        total_loss = self.weight[0]*content_loss + self.weight[1]*style_loss\n",
    "        \n",
    "        return total_loss, content_loss, style_loss\n",
    "    \n",
    "    #딥드림 함수 설계 방법론을 바탕으로 Gradient Descent Step 함수 설계\n",
    "    def gradient_descent_step(self, task):\n",
    "        task.requires_grad = True #teans(tensor)의 기울기 계산 활성화\n",
    "\n",
    "        # 옵티마이저 설정(뉴럴 스타일 트랜스퍼는 LBFGS를 사용)\n",
    "        optimizer = optim.Adam([task], lr= self.lr)\n",
    "\n",
    "        optimizer.zero_grad() #옵티마이저 기울기 0으로 초기화  \n",
    "\n",
    "        #전사 과정 수행\n",
    "        pred_task = self.task_model(task)\n",
    "\n",
    "        # 로스 함수 계산 (전사 결과물을 로스함수로 보낸다.)\n",
    "        total_loss, content_loss, style_loss = self.compute_loss(pred_task)\n",
    "\n",
    "        # 역전파 수행 #retain_graph=True -> 기울기 값 생성\n",
    "        total_loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # 옵티마이저 파라미터가 [task](텐서자료형) 단 하나니 [0]번째 리스트임\n",
    "            for param in optimizer.param_groups[0]['params']:\n",
    "                param.sub_(self.lr * param.grad) #이게 경사 하강법의 코드임\n",
    "                grads_norm = param.grad.norm()\n",
    "                print(grads_norm)\n",
    "\n",
    "        task = task.detach()  # 그래디언트 추적 중단\n",
    "\n",
    "        return task, content_loss.item(), style_loss.item()\n",
    "    \n",
    "\n",
    "    def gradient_descent_loop(self, task, img_shape, normal_val,\n",
    "                              content, style, num_steps=300):\n",
    "        #초기화 함수 구동\n",
    "        self.initalize(content, style)\n",
    "\n",
    "        for step in tqdm(range(num_steps)):\n",
    "            #경사하강법 함수 구동\n",
    "            task, content_loss, style_loss = self.gradient_descent_step(task)\n",
    "\n",
    "            if step % 25 == 0:\n",
    "                # 로스 결과값 산출\n",
    "                print(f\"Step {step}\", end=' ')\n",
    "                print(f\"[콘텐츠 로스: {content_loss:.4f}, \", end=' ')\n",
    "                print(f\"스타일 로스: {style_loss:.4f}]\")\n",
    "\n",
    "                #중간 결과물을 이미지로 저장\n",
    "                step_res = task.detach().clone()\n",
    "                task_img = deprocess_img(step_res, img_shape, normal_val)\n",
    "                name = f'combine_{step}'\n",
    "                task_img.save(f\"{name}.png\")\n",
    "        \n",
    "        return task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_transfer = StyleTransfer(backbone, content_block, style_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1456, device='cuda:0')\n",
      "Step 0 [콘텐츠 로스: 22.3436,  스타일 로스: 0.0053]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300 [00:00<02:51,  1.75it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mstyle_transfer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_descent_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgNet_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mcontent_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle_tensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 87\u001b[0m, in \u001b[0;36mStyleTransfer.gradient_descent_loop\u001b[1;34m(self, task, img_shape, normal_val, content, style, num_steps)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitalize(content, style)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_steps)):\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m#경사하강법 함수 구동\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m     task, content_loss, style_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_descent_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m25\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;66;03m# 로스 결과값 산출\u001b[39;00m\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 66\u001b[0m, in \u001b[0;36mStyleTransfer.gradient_descent_step\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m     63\u001b[0m total_loss, content_loss, style_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(pred_task)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# 역전파 수행 #retain_graph=True -> 기울기 값 생성\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# 옵티마이저 파라미터가 [task](텐서자료형) 단 하나니 [0]번째 리스트임\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\HILS_AMD\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HILS_AMD\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HILS_AMD\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\autograd\\graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "style_transfer.gradient_descent_loop(task_tensor, img_shape, imgNet_val,\n",
    "                                     content_tensor, style_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
