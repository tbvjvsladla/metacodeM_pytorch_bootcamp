{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, **kwargs):\n",
    "        super(conv_block, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, **kwargs)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inception_block(nn.Module):\n",
    "    def __init__(self, in_ch, ch1x1, ch3x3_red, ch3x3, ch5x5_red, ch5x5, pool):\n",
    "        super(inception_block, self).__init__()\n",
    "\n",
    "        self.branch_1 = nn.Conv2d(in_ch, ch1x1, kernel_size=(1,1))\n",
    "\n",
    "        self.branch_2 = nn.Sequential(\n",
    "            conv_block(in_ch, ch3x3_red, kernel_size=(1,1)),\n",
    "            conv_block(ch3x3_red, ch3x3, kernel_size=(3,3), padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch_3 = nn.Sequential(\n",
    "            conv_block(in_ch, ch5x5_red, kernel_size=(1,1)),\n",
    "            conv_block(ch5x5_red, ch5x5, kernel_size=(5,5), padding=2)\n",
    "        )\n",
    "\n",
    "        self.branch_4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=(3,3), stride=1, padding=1),\n",
    "            conv_block(in_ch, pool, kernel_size=(1,1))\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.branch_1(x)\n",
    "        x2 = self.branch_2(x)\n",
    "        x3 = self.branch_3(x)\n",
    "        x4 = self.branch_4(x)\n",
    "\n",
    "        return torch.cat([x1, x2, x3, x4], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, in_ch=3, num_classes=1000):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "\n",
    "        self.conv1 = conv_block(in_ch=in_ch, out_ch=64, kernel_size=(7,7), stride=2, padding=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.conv2 = conv_block(64, 192, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.inception_3a = inception_block(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception_3b = inception_block(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool_3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.inception_4a = inception_block(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception_4b = inception_block(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception_4c = inception_block(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception_4d = inception_block(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception_4e = inception_block(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.maxpool_4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.inception_5a = inception_block(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception_5b = inception_block(832, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
    "        self.dropout = nn.Dropout2d(p=0.4)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = self.inception_3a(x)\n",
    "        x = self.inception_3b(x)\n",
    "        x = self.maxpool_3(x)\n",
    "\n",
    "        x = self.inception_4a(x)\n",
    "        x = self.inception_4b(x)\n",
    "        x = self.inception_4c(x)\n",
    "        x = self.inception_4d(x)\n",
    "        x = self.inception_4e(x)\n",
    "        x = self.maxpool_4(x)\n",
    "\n",
    "        x = self.inception_5a(x)\n",
    "        x = self.inception_5b(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여기까지가 보조분류기가 없는 GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gooLeNet의 inception모듈 만들기\n",
    "\n",
    "class Inception_module(nn.Module):\n",
    "    def __init__(self, in_channels, ch1x1, ch3x3_red, ch3x3, ch5x5_red, ch5x5, pool):\n",
    "        super(Inception_module, self).__init__()\n",
    "\n",
    "        #1번째 네트워크\n",
    "        self.conv1x1 = nn.Conv2d(in_channels, ch1x1, kernel_size=1)\n",
    "\n",
    "        #2번째 네트워크\n",
    "        self.conv3x3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, ch3x3_red, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch3x3_red, ch3x3, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        #3번째 네트워크\n",
    "        self.conv5x5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, ch5x5_red, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch5x5_red, ch5x5, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        #4번째 네트워크\n",
    "        self.pool_net = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels, pool, kernel_size=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1x1(x)\n",
    "        x2 = self.conv3x3(x)\n",
    "        x3 = self.conv5x5(x)\n",
    "        x4 = self.pool_net(x)\n",
    "\n",
    "        return torch.cat([x1, x2, x3, x4], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이거는 GoogLeNet설계하면서 필요한 네트워크 블록임.. 이거는 뭔지 잘 모르겟음..\n",
    "#보조분류기 라는 거 같은데 모르겟음?\n",
    "\n",
    "class AuxModule(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=1000):\n",
    "        super(AuxModule, self).__init__()\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((4,4))\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 128, kernel_size=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(4*4*128, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.7),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avgpool(x)\n",
    "        x = self.conv1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#위 설계한 inception모듈을 받아서 전체 GoogLeNet설계하기\n",
    "\n",
    "\n",
    "class GoogLeNet_withAux(torch.nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=1000):\n",
    "        super(GoogLeNet_withAux, self).__init__()\n",
    "\n",
    "        self.training = True\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.LocalResponseNorm(2)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.inception_3a = Inception_module(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception_3b = Inception_module(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool_3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.inception_4a = Inception_module(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.aux1 = AuxModule(512, num_classes)\n",
    "\n",
    "        self.inception_4b = Inception_module(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception_4c = Inception_module(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception_4d = Inception_module(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.aux2 = AuxModule(528, num_classes)\n",
    "\n",
    "        self.inception_4e = Inception_module(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.maxpool_4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.inception_5a = Inception_module(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception_5b = Inception_module(832, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout2d(p=0.4)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        x = self.inception_3a(x)\n",
    "        x = self.inception_3b(x)\n",
    "        x = self.maxpool_3(x)\n",
    "\n",
    "        x = self.inception_4a(x)\n",
    "        if self.training:\n",
    "            out1 = self.aux1(x)\n",
    "\n",
    "        x = self.inception_4b(x)\n",
    "        x = self.inception_4c(x)\n",
    "        x = self.inception_4d(x)\n",
    "        if self.training:\n",
    "            out2 = self.aux2(x)\n",
    "\n",
    "        x = self.inception_4e(x)\n",
    "        x = self.maxpool_4(x)\n",
    "\n",
    "        x = self.inception_5a(x)\n",
    "        x = self.inception_5b(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)                \n",
    "        if self.training:\n",
    "            return [x, out1, out2]\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    # 훈련 모드 설정\n",
    "    def set_train(self):\n",
    "        self.train()  # 내장 train 메서드를 호출\n",
    "\n",
    "    # 평가 모드 설정\n",
    "    def set_eval(self):\n",
    "        self.eval()  # 내장 eval 메서드를 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "        conv_block-4         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-5           [-1, 64, 56, 56]               0\n",
      "            Conv2d-6          [-1, 192, 56, 56]         110,784\n",
      "       BatchNorm2d-7          [-1, 192, 56, 56]             384\n",
      "              ReLU-8          [-1, 192, 56, 56]               0\n",
      "        conv_block-9          [-1, 192, 56, 56]               0\n",
      "        MaxPool2d-10          [-1, 192, 28, 28]               0\n",
      "           Conv2d-11           [-1, 64, 28, 28]          12,352\n",
      "           Conv2d-12           [-1, 96, 28, 28]          18,528\n",
      "      BatchNorm2d-13           [-1, 96, 28, 28]             192\n",
      "             ReLU-14           [-1, 96, 28, 28]               0\n",
      "       conv_block-15           [-1, 96, 28, 28]               0\n",
      "           Conv2d-16          [-1, 128, 28, 28]         110,720\n",
      "      BatchNorm2d-17          [-1, 128, 28, 28]             256\n",
      "             ReLU-18          [-1, 128, 28, 28]               0\n",
      "       conv_block-19          [-1, 128, 28, 28]               0\n",
      "           Conv2d-20           [-1, 16, 28, 28]           3,088\n",
      "      BatchNorm2d-21           [-1, 16, 28, 28]              32\n",
      "             ReLU-22           [-1, 16, 28, 28]               0\n",
      "       conv_block-23           [-1, 16, 28, 28]               0\n",
      "           Conv2d-24           [-1, 32, 28, 28]          12,832\n",
      "      BatchNorm2d-25           [-1, 32, 28, 28]              64\n",
      "             ReLU-26           [-1, 32, 28, 28]               0\n",
      "       conv_block-27           [-1, 32, 28, 28]               0\n",
      "        MaxPool2d-28          [-1, 192, 28, 28]               0\n",
      "           Conv2d-29           [-1, 32, 28, 28]           6,176\n",
      "      BatchNorm2d-30           [-1, 32, 28, 28]              64\n",
      "             ReLU-31           [-1, 32, 28, 28]               0\n",
      "       conv_block-32           [-1, 32, 28, 28]               0\n",
      "  inception_block-33          [-1, 256, 28, 28]               0\n",
      "           Conv2d-34          [-1, 128, 28, 28]          32,896\n",
      "           Conv2d-35          [-1, 128, 28, 28]          32,896\n",
      "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
      "             ReLU-37          [-1, 128, 28, 28]               0\n",
      "       conv_block-38          [-1, 128, 28, 28]               0\n",
      "           Conv2d-39          [-1, 192, 28, 28]         221,376\n",
      "      BatchNorm2d-40          [-1, 192, 28, 28]             384\n",
      "             ReLU-41          [-1, 192, 28, 28]               0\n",
      "       conv_block-42          [-1, 192, 28, 28]               0\n",
      "           Conv2d-43           [-1, 32, 28, 28]           8,224\n",
      "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
      "             ReLU-45           [-1, 32, 28, 28]               0\n",
      "       conv_block-46           [-1, 32, 28, 28]               0\n",
      "           Conv2d-47           [-1, 96, 28, 28]          76,896\n",
      "      BatchNorm2d-48           [-1, 96, 28, 28]             192\n",
      "             ReLU-49           [-1, 96, 28, 28]               0\n",
      "       conv_block-50           [-1, 96, 28, 28]               0\n",
      "        MaxPool2d-51          [-1, 256, 28, 28]               0\n",
      "           Conv2d-52           [-1, 64, 28, 28]          16,448\n",
      "      BatchNorm2d-53           [-1, 64, 28, 28]             128\n",
      "             ReLU-54           [-1, 64, 28, 28]               0\n",
      "       conv_block-55           [-1, 64, 28, 28]               0\n",
      "  inception_block-56          [-1, 480, 28, 28]               0\n",
      "        MaxPool2d-57          [-1, 480, 14, 14]               0\n",
      "           Conv2d-58          [-1, 192, 14, 14]          92,352\n",
      "           Conv2d-59           [-1, 96, 14, 14]          46,176\n",
      "      BatchNorm2d-60           [-1, 96, 14, 14]             192\n",
      "             ReLU-61           [-1, 96, 14, 14]               0\n",
      "       conv_block-62           [-1, 96, 14, 14]               0\n",
      "           Conv2d-63          [-1, 208, 14, 14]         179,920\n",
      "      BatchNorm2d-64          [-1, 208, 14, 14]             416\n",
      "             ReLU-65          [-1, 208, 14, 14]               0\n",
      "       conv_block-66          [-1, 208, 14, 14]               0\n",
      "           Conv2d-67           [-1, 16, 14, 14]           7,696\n",
      "      BatchNorm2d-68           [-1, 16, 14, 14]              32\n",
      "             ReLU-69           [-1, 16, 14, 14]               0\n",
      "       conv_block-70           [-1, 16, 14, 14]               0\n",
      "           Conv2d-71           [-1, 48, 14, 14]          19,248\n",
      "      BatchNorm2d-72           [-1, 48, 14, 14]              96\n",
      "             ReLU-73           [-1, 48, 14, 14]               0\n",
      "       conv_block-74           [-1, 48, 14, 14]               0\n",
      "        MaxPool2d-75          [-1, 480, 14, 14]               0\n",
      "           Conv2d-76           [-1, 64, 14, 14]          30,784\n",
      "      BatchNorm2d-77           [-1, 64, 14, 14]             128\n",
      "             ReLU-78           [-1, 64, 14, 14]               0\n",
      "       conv_block-79           [-1, 64, 14, 14]               0\n",
      "  inception_block-80          [-1, 512, 14, 14]               0\n",
      "           Conv2d-81          [-1, 160, 14, 14]          82,080\n",
      "           Conv2d-82          [-1, 112, 14, 14]          57,456\n",
      "      BatchNorm2d-83          [-1, 112, 14, 14]             224\n",
      "             ReLU-84          [-1, 112, 14, 14]               0\n",
      "       conv_block-85          [-1, 112, 14, 14]               0\n",
      "           Conv2d-86          [-1, 224, 14, 14]         226,016\n",
      "      BatchNorm2d-87          [-1, 224, 14, 14]             448\n",
      "             ReLU-88          [-1, 224, 14, 14]               0\n",
      "       conv_block-89          [-1, 224, 14, 14]               0\n",
      "           Conv2d-90           [-1, 24, 14, 14]          12,312\n",
      "      BatchNorm2d-91           [-1, 24, 14, 14]              48\n",
      "             ReLU-92           [-1, 24, 14, 14]               0\n",
      "       conv_block-93           [-1, 24, 14, 14]               0\n",
      "           Conv2d-94           [-1, 64, 14, 14]          38,464\n",
      "      BatchNorm2d-95           [-1, 64, 14, 14]             128\n",
      "             ReLU-96           [-1, 64, 14, 14]               0\n",
      "       conv_block-97           [-1, 64, 14, 14]               0\n",
      "        MaxPool2d-98          [-1, 512, 14, 14]               0\n",
      "           Conv2d-99           [-1, 64, 14, 14]          32,832\n",
      "     BatchNorm2d-100           [-1, 64, 14, 14]             128\n",
      "            ReLU-101           [-1, 64, 14, 14]               0\n",
      "      conv_block-102           [-1, 64, 14, 14]               0\n",
      " inception_block-103          [-1, 512, 14, 14]               0\n",
      "          Conv2d-104          [-1, 128, 14, 14]          65,664\n",
      "          Conv2d-105          [-1, 128, 14, 14]          65,664\n",
      "     BatchNorm2d-106          [-1, 128, 14, 14]             256\n",
      "            ReLU-107          [-1, 128, 14, 14]               0\n",
      "      conv_block-108          [-1, 128, 14, 14]               0\n",
      "          Conv2d-109          [-1, 256, 14, 14]         295,168\n",
      "     BatchNorm2d-110          [-1, 256, 14, 14]             512\n",
      "            ReLU-111          [-1, 256, 14, 14]               0\n",
      "      conv_block-112          [-1, 256, 14, 14]               0\n",
      "          Conv2d-113           [-1, 24, 14, 14]          12,312\n",
      "     BatchNorm2d-114           [-1, 24, 14, 14]              48\n",
      "            ReLU-115           [-1, 24, 14, 14]               0\n",
      "      conv_block-116           [-1, 24, 14, 14]               0\n",
      "          Conv2d-117           [-1, 64, 14, 14]          38,464\n",
      "     BatchNorm2d-118           [-1, 64, 14, 14]             128\n",
      "            ReLU-119           [-1, 64, 14, 14]               0\n",
      "      conv_block-120           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-121          [-1, 512, 14, 14]               0\n",
      "          Conv2d-122           [-1, 64, 14, 14]          32,832\n",
      "     BatchNorm2d-123           [-1, 64, 14, 14]             128\n",
      "            ReLU-124           [-1, 64, 14, 14]               0\n",
      "      conv_block-125           [-1, 64, 14, 14]               0\n",
      " inception_block-126          [-1, 512, 14, 14]               0\n",
      "          Conv2d-127          [-1, 112, 14, 14]          57,456\n",
      "          Conv2d-128          [-1, 144, 14, 14]          73,872\n",
      "     BatchNorm2d-129          [-1, 144, 14, 14]             288\n",
      "            ReLU-130          [-1, 144, 14, 14]               0\n",
      "      conv_block-131          [-1, 144, 14, 14]               0\n",
      "          Conv2d-132          [-1, 288, 14, 14]         373,536\n",
      "     BatchNorm2d-133          [-1, 288, 14, 14]             576\n",
      "            ReLU-134          [-1, 288, 14, 14]               0\n",
      "      conv_block-135          [-1, 288, 14, 14]               0\n",
      "          Conv2d-136           [-1, 32, 14, 14]          16,416\n",
      "     BatchNorm2d-137           [-1, 32, 14, 14]              64\n",
      "            ReLU-138           [-1, 32, 14, 14]               0\n",
      "      conv_block-139           [-1, 32, 14, 14]               0\n",
      "          Conv2d-140           [-1, 64, 14, 14]          51,264\n",
      "     BatchNorm2d-141           [-1, 64, 14, 14]             128\n",
      "            ReLU-142           [-1, 64, 14, 14]               0\n",
      "      conv_block-143           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-144          [-1, 512, 14, 14]               0\n",
      "          Conv2d-145           [-1, 64, 14, 14]          32,832\n",
      "     BatchNorm2d-146           [-1, 64, 14, 14]             128\n",
      "            ReLU-147           [-1, 64, 14, 14]               0\n",
      "      conv_block-148           [-1, 64, 14, 14]               0\n",
      " inception_block-149          [-1, 528, 14, 14]               0\n",
      "          Conv2d-150          [-1, 256, 14, 14]         135,424\n",
      "          Conv2d-151          [-1, 160, 14, 14]          84,640\n",
      "     BatchNorm2d-152          [-1, 160, 14, 14]             320\n",
      "            ReLU-153          [-1, 160, 14, 14]               0\n",
      "      conv_block-154          [-1, 160, 14, 14]               0\n",
      "          Conv2d-155          [-1, 320, 14, 14]         461,120\n",
      "     BatchNorm2d-156          [-1, 320, 14, 14]             640\n",
      "            ReLU-157          [-1, 320, 14, 14]               0\n",
      "      conv_block-158          [-1, 320, 14, 14]               0\n",
      "          Conv2d-159           [-1, 32, 14, 14]          16,928\n",
      "     BatchNorm2d-160           [-1, 32, 14, 14]              64\n",
      "            ReLU-161           [-1, 32, 14, 14]               0\n",
      "      conv_block-162           [-1, 32, 14, 14]               0\n",
      "          Conv2d-163          [-1, 128, 14, 14]         102,528\n",
      "     BatchNorm2d-164          [-1, 128, 14, 14]             256\n",
      "            ReLU-165          [-1, 128, 14, 14]               0\n",
      "      conv_block-166          [-1, 128, 14, 14]               0\n",
      "       MaxPool2d-167          [-1, 528, 14, 14]               0\n",
      "          Conv2d-168          [-1, 128, 14, 14]          67,712\n",
      "     BatchNorm2d-169          [-1, 128, 14, 14]             256\n",
      "            ReLU-170          [-1, 128, 14, 14]               0\n",
      "      conv_block-171          [-1, 128, 14, 14]               0\n",
      " inception_block-172          [-1, 832, 14, 14]               0\n",
      "       MaxPool2d-173            [-1, 832, 7, 7]               0\n",
      "          Conv2d-174            [-1, 256, 7, 7]         213,248\n",
      "          Conv2d-175            [-1, 160, 7, 7]         133,280\n",
      "     BatchNorm2d-176            [-1, 160, 7, 7]             320\n",
      "            ReLU-177            [-1, 160, 7, 7]               0\n",
      "      conv_block-178            [-1, 160, 7, 7]               0\n",
      "          Conv2d-179            [-1, 320, 7, 7]         461,120\n",
      "     BatchNorm2d-180            [-1, 320, 7, 7]             640\n",
      "            ReLU-181            [-1, 320, 7, 7]               0\n",
      "      conv_block-182            [-1, 320, 7, 7]               0\n",
      "          Conv2d-183             [-1, 32, 7, 7]          26,656\n",
      "     BatchNorm2d-184             [-1, 32, 7, 7]              64\n",
      "            ReLU-185             [-1, 32, 7, 7]               0\n",
      "      conv_block-186             [-1, 32, 7, 7]               0\n",
      "          Conv2d-187            [-1, 128, 7, 7]         102,528\n",
      "     BatchNorm2d-188            [-1, 128, 7, 7]             256\n",
      "            ReLU-189            [-1, 128, 7, 7]               0\n",
      "      conv_block-190            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-191            [-1, 832, 7, 7]               0\n",
      "          Conv2d-192            [-1, 128, 7, 7]         106,624\n",
      "     BatchNorm2d-193            [-1, 128, 7, 7]             256\n",
      "            ReLU-194            [-1, 128, 7, 7]               0\n",
      "      conv_block-195            [-1, 128, 7, 7]               0\n",
      " inception_block-196            [-1, 832, 7, 7]               0\n",
      "          Conv2d-197            [-1, 384, 7, 7]         319,872\n",
      "          Conv2d-198            [-1, 192, 7, 7]         159,936\n",
      "     BatchNorm2d-199            [-1, 192, 7, 7]             384\n",
      "            ReLU-200            [-1, 192, 7, 7]               0\n",
      "      conv_block-201            [-1, 192, 7, 7]               0\n",
      "          Conv2d-202            [-1, 384, 7, 7]         663,936\n",
      "     BatchNorm2d-203            [-1, 384, 7, 7]             768\n",
      "            ReLU-204            [-1, 384, 7, 7]               0\n",
      "      conv_block-205            [-1, 384, 7, 7]               0\n",
      "          Conv2d-206             [-1, 48, 7, 7]          39,984\n",
      "     BatchNorm2d-207             [-1, 48, 7, 7]              96\n",
      "            ReLU-208             [-1, 48, 7, 7]               0\n",
      "      conv_block-209             [-1, 48, 7, 7]               0\n",
      "          Conv2d-210            [-1, 128, 7, 7]         153,728\n",
      "     BatchNorm2d-211            [-1, 128, 7, 7]             256\n",
      "            ReLU-212            [-1, 128, 7, 7]               0\n",
      "      conv_block-213            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-214            [-1, 832, 7, 7]               0\n",
      "          Conv2d-215            [-1, 128, 7, 7]         106,624\n",
      "     BatchNorm2d-216            [-1, 128, 7, 7]             256\n",
      "            ReLU-217            [-1, 128, 7, 7]               0\n",
      "      conv_block-218            [-1, 128, 7, 7]               0\n",
      " inception_block-219           [-1, 1024, 7, 7]               0\n",
      "       AvgPool2d-220           [-1, 1024, 1, 1]               0\n",
      "       Dropout2d-221                 [-1, 1024]               0\n",
      "          Linear-222                 [-1, 1000]       1,025,000\n",
      "================================================================\n",
      "Total params: 7,005,464\n",
      "Trainable params: 7,005,464\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 104.63\n",
      "Params size (MB): 26.72\n",
      "Estimated Total Size (MB): 131.92\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Z13_ASH\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\functional.py:1374: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "\n",
    "debug_model = GoogLeNet()\n",
    "torchsummary.summary(debug_model, input_size=(3, 224, 224), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
      "              ReLU-2         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-3           [-1, 64, 56, 56]               0\n",
      " LocalResponseNorm-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,160\n",
      "              ReLU-6           [-1, 64, 56, 56]               0\n",
      "            Conv2d-7          [-1, 192, 56, 56]         110,784\n",
      "              ReLU-8          [-1, 192, 56, 56]               0\n",
      " LocalResponseNorm-9          [-1, 192, 56, 56]               0\n",
      "        MaxPool2d-10          [-1, 192, 28, 28]               0\n",
      "           Conv2d-11           [-1, 64, 28, 28]          12,352\n",
      "           Conv2d-12           [-1, 96, 28, 28]          18,528\n",
      "             ReLU-13           [-1, 96, 28, 28]               0\n",
      "           Conv2d-14          [-1, 128, 28, 28]         110,720\n",
      "             ReLU-15          [-1, 128, 28, 28]               0\n",
      "           Conv2d-16           [-1, 16, 28, 28]           3,088\n",
      "             ReLU-17           [-1, 16, 28, 28]               0\n",
      "           Conv2d-18           [-1, 32, 28, 28]          12,832\n",
      "             ReLU-19           [-1, 32, 28, 28]               0\n",
      "        MaxPool2d-20          [-1, 192, 28, 28]               0\n",
      "           Conv2d-21           [-1, 32, 28, 28]           6,176\n",
      "             ReLU-22           [-1, 32, 28, 28]               0\n",
      " Inception_module-23          [-1, 256, 28, 28]               0\n",
      "           Conv2d-24          [-1, 128, 28, 28]          32,896\n",
      "           Conv2d-25          [-1, 128, 28, 28]          32,896\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "           Conv2d-27          [-1, 192, 28, 28]         221,376\n",
      "             ReLU-28          [-1, 192, 28, 28]               0\n",
      "           Conv2d-29           [-1, 32, 28, 28]           8,224\n",
      "             ReLU-30           [-1, 32, 28, 28]               0\n",
      "           Conv2d-31           [-1, 96, 28, 28]          76,896\n",
      "             ReLU-32           [-1, 96, 28, 28]               0\n",
      "        MaxPool2d-33          [-1, 256, 28, 28]               0\n",
      "           Conv2d-34           [-1, 64, 28, 28]          16,448\n",
      "             ReLU-35           [-1, 64, 28, 28]               0\n",
      " Inception_module-36          [-1, 480, 28, 28]               0\n",
      "        MaxPool2d-37          [-1, 480, 14, 14]               0\n",
      "           Conv2d-38          [-1, 192, 14, 14]          92,352\n",
      "           Conv2d-39           [-1, 96, 14, 14]          46,176\n",
      "             ReLU-40           [-1, 96, 14, 14]               0\n",
      "           Conv2d-41          [-1, 208, 14, 14]         179,920\n",
      "             ReLU-42          [-1, 208, 14, 14]               0\n",
      "           Conv2d-43           [-1, 16, 14, 14]           7,696\n",
      "             ReLU-44           [-1, 16, 14, 14]               0\n",
      "           Conv2d-45           [-1, 48, 14, 14]          19,248\n",
      "             ReLU-46           [-1, 48, 14, 14]               0\n",
      "        MaxPool2d-47          [-1, 480, 14, 14]               0\n",
      "           Conv2d-48           [-1, 64, 14, 14]          30,784\n",
      "             ReLU-49           [-1, 64, 14, 14]               0\n",
      " Inception_module-50          [-1, 512, 14, 14]               0\n",
      "AdaptiveAvgPool2d-51            [-1, 512, 4, 4]               0\n",
      "           Conv2d-52            [-1, 128, 4, 4]          65,664\n",
      "             ReLU-53            [-1, 128, 4, 4]               0\n",
      "           Linear-54                 [-1, 1024]       2,098,176\n",
      "             ReLU-55                 [-1, 1024]               0\n",
      "        Dropout2d-56                 [-1, 1024]               0\n",
      "           Linear-57                 [-1, 1000]       1,025,000\n",
      "        AuxModule-58                 [-1, 1000]               0\n",
      "           Conv2d-59          [-1, 160, 14, 14]          82,080\n",
      "           Conv2d-60          [-1, 112, 14, 14]          57,456\n",
      "             ReLU-61          [-1, 112, 14, 14]               0\n",
      "           Conv2d-62          [-1, 224, 14, 14]         226,016\n",
      "             ReLU-63          [-1, 224, 14, 14]               0\n",
      "           Conv2d-64           [-1, 24, 14, 14]          12,312\n",
      "             ReLU-65           [-1, 24, 14, 14]               0\n",
      "           Conv2d-66           [-1, 64, 14, 14]          38,464\n",
      "             ReLU-67           [-1, 64, 14, 14]               0\n",
      "        MaxPool2d-68          [-1, 512, 14, 14]               0\n",
      "           Conv2d-69           [-1, 64, 14, 14]          32,832\n",
      "             ReLU-70           [-1, 64, 14, 14]               0\n",
      " Inception_module-71          [-1, 512, 14, 14]               0\n",
      "           Conv2d-72          [-1, 128, 14, 14]          65,664\n",
      "           Conv2d-73          [-1, 128, 14, 14]          65,664\n",
      "             ReLU-74          [-1, 128, 14, 14]               0\n",
      "           Conv2d-75          [-1, 256, 14, 14]         295,168\n",
      "             ReLU-76          [-1, 256, 14, 14]               0\n",
      "           Conv2d-77           [-1, 24, 14, 14]          12,312\n",
      "             ReLU-78           [-1, 24, 14, 14]               0\n",
      "           Conv2d-79           [-1, 64, 14, 14]          38,464\n",
      "             ReLU-80           [-1, 64, 14, 14]               0\n",
      "        MaxPool2d-81          [-1, 512, 14, 14]               0\n",
      "           Conv2d-82           [-1, 64, 14, 14]          32,832\n",
      "             ReLU-83           [-1, 64, 14, 14]               0\n",
      " Inception_module-84          [-1, 512, 14, 14]               0\n",
      "           Conv2d-85          [-1, 112, 14, 14]          57,456\n",
      "           Conv2d-86          [-1, 144, 14, 14]          73,872\n",
      "             ReLU-87          [-1, 144, 14, 14]               0\n",
      "           Conv2d-88          [-1, 288, 14, 14]         373,536\n",
      "             ReLU-89          [-1, 288, 14, 14]               0\n",
      "           Conv2d-90           [-1, 32, 14, 14]          16,416\n",
      "             ReLU-91           [-1, 32, 14, 14]               0\n",
      "           Conv2d-92           [-1, 64, 14, 14]          51,264\n",
      "             ReLU-93           [-1, 64, 14, 14]               0\n",
      "        MaxPool2d-94          [-1, 512, 14, 14]               0\n",
      "           Conv2d-95           [-1, 64, 14, 14]          32,832\n",
      "             ReLU-96           [-1, 64, 14, 14]               0\n",
      " Inception_module-97          [-1, 528, 14, 14]               0\n",
      "AdaptiveAvgPool2d-98            [-1, 528, 4, 4]               0\n",
      "           Conv2d-99            [-1, 128, 4, 4]          67,712\n",
      "            ReLU-100            [-1, 128, 4, 4]               0\n",
      "          Linear-101                 [-1, 1024]       2,098,176\n",
      "            ReLU-102                 [-1, 1024]               0\n",
      "       Dropout2d-103                 [-1, 1024]               0\n",
      "          Linear-104                 [-1, 1000]       1,025,000\n",
      "       AuxModule-105                 [-1, 1000]               0\n",
      "          Conv2d-106          [-1, 256, 14, 14]         135,424\n",
      "          Conv2d-107          [-1, 160, 14, 14]          84,640\n",
      "            ReLU-108          [-1, 160, 14, 14]               0\n",
      "          Conv2d-109          [-1, 320, 14, 14]         461,120\n",
      "            ReLU-110          [-1, 320, 14, 14]               0\n",
      "          Conv2d-111           [-1, 32, 14, 14]          16,928\n",
      "            ReLU-112           [-1, 32, 14, 14]               0\n",
      "          Conv2d-113          [-1, 128, 14, 14]         102,528\n",
      "            ReLU-114          [-1, 128, 14, 14]               0\n",
      "       MaxPool2d-115          [-1, 528, 14, 14]               0\n",
      "          Conv2d-116          [-1, 128, 14, 14]          67,712\n",
      "            ReLU-117          [-1, 128, 14, 14]               0\n",
      "Inception_module-118          [-1, 832, 14, 14]               0\n",
      "       MaxPool2d-119            [-1, 832, 7, 7]               0\n",
      "          Conv2d-120            [-1, 256, 7, 7]         213,248\n",
      "          Conv2d-121            [-1, 160, 7, 7]         133,280\n",
      "            ReLU-122            [-1, 160, 7, 7]               0\n",
      "          Conv2d-123            [-1, 320, 7, 7]         461,120\n",
      "            ReLU-124            [-1, 320, 7, 7]               0\n",
      "          Conv2d-125             [-1, 32, 7, 7]          26,656\n",
      "            ReLU-126             [-1, 32, 7, 7]               0\n",
      "          Conv2d-127            [-1, 128, 7, 7]         102,528\n",
      "            ReLU-128            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-129            [-1, 832, 7, 7]               0\n",
      "          Conv2d-130            [-1, 128, 7, 7]         106,624\n",
      "            ReLU-131            [-1, 128, 7, 7]               0\n",
      "Inception_module-132            [-1, 832, 7, 7]               0\n",
      "          Conv2d-133            [-1, 384, 7, 7]         319,872\n",
      "          Conv2d-134            [-1, 192, 7, 7]         159,936\n",
      "            ReLU-135            [-1, 192, 7, 7]               0\n",
      "          Conv2d-136            [-1, 384, 7, 7]         663,936\n",
      "            ReLU-137            [-1, 384, 7, 7]               0\n",
      "          Conv2d-138             [-1, 48, 7, 7]          39,984\n",
      "            ReLU-139             [-1, 48, 7, 7]               0\n",
      "          Conv2d-140            [-1, 128, 7, 7]         153,728\n",
      "            ReLU-141            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-142            [-1, 832, 7, 7]               0\n",
      "          Conv2d-143            [-1, 128, 7, 7]         106,624\n",
      "            ReLU-144            [-1, 128, 7, 7]               0\n",
      "Inception_module-145           [-1, 1024, 7, 7]               0\n",
      "AdaptiveAvgPool2d-146           [-1, 1024, 1, 1]               0\n",
      "       Dropout2d-147                 [-1, 1024]               0\n",
      "          Linear-148                 [-1, 1000]       1,025,000\n",
      "================================================================\n",
      "Total params: 13,378,280\n",
      "Trainable params: 13,378,280\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 73.23\n",
      "Params size (MB): 51.03\n",
      "Estimated Total Size (MB): 124.84\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "debug_model_2 = GoogLeNet_withAux()\n",
    "torchsummary.summary(debug_model_2, input_size=(3, 224, 224), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여기까지가 보조분류기(AuxModule) 있는 GoogLeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 여기는 공통의 데이터 전처리 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision #예제 이미지 데이터셋이 모여있는 모듈\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to raw_data\\cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169001437/169001437 [00:45<00:00, 3715643.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting raw_data\\cifar-100-python.tar.gz to raw_data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_raw_data = datasets.CIFAR100(\"raw_data\", \n",
    "                                   train=True, \n",
    "                                   download=True, \n",
    "                                   transform=transforms.ToTensor())\n",
    "test_raw_data = datasets.CIFAR100(\"raw_data\", \n",
    "                                   train=False, \n",
    "                                   download=True, \n",
    "                                   transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean: ['0.507', '0.487', '0.441'], Train Std: ['0.201', '0.198', '0.202']\n",
      "Test Mean: ['0.509', '0.487', '0.442'], Test Std: ['0.202', '0.200', '0.204']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#이미지 전처리11 : RGB채널별 평균/표준편차 계산 함수 설계\n",
    "def normal_parm_func(input_data):\n",
    "\n",
    "    meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x, _ in input_data]\n",
    "    stdRGB = [np.std(x.numpy(), axis=(1,2)) for x, _ in input_data]\n",
    "\n",
    "    RGB_mean_list, RGB_std_list = [], []\n",
    "\n",
    "    for i in range(3):\n",
    "        RGB_mean_list.append(\n",
    "            np.mean([m[i] for m in meanRGB])\n",
    "        )\n",
    "        RGB_std_list.append(\n",
    "            np.mean([s[i] for s in stdRGB])\n",
    "        )\n",
    "\n",
    "    return RGB_mean_list, RGB_std_list\n",
    "\n",
    "\n",
    "proc_train_data = normal_parm_func(train_raw_data)\n",
    "proc_test_data = normal_parm_func(test_raw_data)\n",
    "\n",
    "print(f\"Train Mean: {[format(m, '.3f') for m in proc_train_data[0]]}, \"\n",
    "      f\"Train Std: {[format(s, '.3f') for s in proc_train_data[1]]}\")\n",
    "print(f\"Test Mean: {[format(m, '.3f') for m in proc_test_data[0]]}, \"\n",
    "      f\"Test Std: {[format(s, '.3f') for s in proc_test_data[1]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 변환방식이 저장된 객체 생성\n",
    "train_transformation = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    #입력하려는 train_raw데이터가 텐서 자료형이지만\n",
    "    #이걸 안써주면 PIL자료형이 되버림...\n",
    "    transforms.Resize((224, 224)), #GooGleNet 입력 이미지는 224 224 3임\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Normalize(mean=proc_train_data[0], std=proc_train_data[1])\n",
    "    #훈련데이터의 평균, 표준편차 입력\n",
    "])\n",
    "test_transformation = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)), #GooGleNet 입력 이미지는 224 224 3임\n",
    "    transforms.Normalize(mean=proc_train_data[0], std=proc_train_data[1])\n",
    "    #훈련데이터의 평균, 표준편차 입력\n",
    "])\n",
    "\n",
    "#이미지에 위 변환방식을 적용\n",
    "train_raw_data.transform = train_transformation\n",
    "test_raw_data.transform = test_transformation\n",
    "\n",
    "#데이터 로더 생성 -> 여기서 Batch_size를 정의함\n",
    "train_loader = torch.utils.data.DataLoader(train_raw_data, batch_size=48, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_raw_data, batch_size=48, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images: 50000, Unique Labels: 100\n",
      "Testing Images: 10000, Unique Labels: 100\n"
     ]
    }
   ],
   "source": [
    "def count_images_and_labels(loader):\n",
    "    num_images = 0\n",
    "    label_set = set()\n",
    "    for data, labels in loader:\n",
    "        num_images += data.size(0)\n",
    "        label_set.update(labels.tolist())\n",
    "    \n",
    "    return num_images, len(label_set)\n",
    "\n",
    "\n",
    "train_images, train_label_count = count_images_and_labels(train_loader)\n",
    "test_images, test_label_count = count_images_and_labels(test_loader)\n",
    "\n",
    "print(f\"Training Images: {train_images}, Unique Labels: {train_label_count}\")\n",
    "print(f\"Testing Images: {test_images}, Unique Labels: {test_label_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 보조분류기 없는 GoogLeNet먼저 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GoogLeNet(\n",
       "  (conv1): conv_block(\n",
       "    (relu): ReLU()\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (conv2): conv_block(\n",
       "    (relu): ReLU()\n",
       "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (inception_3a): inception_block(\n",
       "    (branch_1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch_2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch_3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch_4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception_3b): inception_block(\n",
       "    (branch_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch_2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch_3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch_4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool_3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (inception_4a): inception_block(\n",
       "    (branch_1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch_2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch_3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch_4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception_4b): inception_block(\n",
       "    (branch_1): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch_2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch_3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch_4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception_4c): inception_block(\n",
       "    (branch_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch_2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch_3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch_4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception_4d): inception_block(\n",
       "    (branch_1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch_2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch_3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch_4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception_4e): inception_block(\n",
       "    (branch_1): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch_2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch_3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch_4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool_4): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (inception_5a): inception_block(\n",
       "    (branch_1): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch_2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch_3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch_4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception_5b): inception_block(\n",
       "    (branch_1): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch_2): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch_3): Sequential(\n",
       "      (0): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch_4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=(3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): conv_block(\n",
       "        (relu): ReLU()\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (dropout): Dropout2d(p=0.4, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_model = GoogLeNet(in_ch= 3, num_classes=train_label_count)\n",
    "ex_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0002\n",
    "\n",
    "import torch.nn.functional as F #이거는 활성화 함수 모듈\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(ex_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련을 위한 함수 정의\n",
    "from tqdm import tqdm #훈련 진행상황 체크\n",
    "\n",
    "def model_train(model, data_loader, loss_fn, optimizer_fn, processing_device):\n",
    "\n",
    "    model.train() #모델을 훈련 모드로 설정\n",
    "\n",
    "    #loss와 accuracy를 계산하기 위한 임시 변수를 생성\n",
    "    run_size, run_loss, corr = 0, 0, 0\n",
    "\n",
    "    progress_bar = tqdm(data_loader) #이때 사용되는 데이터는 훈련용 데이터\n",
    "\n",
    "\n",
    "    for batch_idx, (image, label) in enumerate(progress_bar, start=1):\n",
    "        #입력된 데이터를 먼저 GPU로 이전하기\n",
    "        image = image.to(processing_device)\n",
    "        label = label.to(processing_device)\n",
    "\n",
    "        #전사과정 수행\n",
    "        output = model(image)\n",
    "\n",
    "        loss = loss_fn(output, label)\n",
    "\n",
    "        #옵티마이저의 Gradient 초기화\n",
    "        optimizer_fn.zero_grad()\n",
    "\n",
    "        #backward 과정 수행\n",
    "        loss.backward() #Backprogration을 진행하여 Gradient계산\n",
    "        optimizer_fn.step() #계산된 gradient(모델 파라미터)를 업데이트\n",
    "\n",
    "\n",
    "        #여기부터는 학습이 잘 되고 있는지 확인하는 부분\n",
    "        _, pred = output.max(dim=1)\n",
    "        corr += pred.eq(label).sum().item()\n",
    "        \n",
    "        run_loss += loss.item() * image.size(0)\n",
    "        run_size += image.size(0)\n",
    "        progress_bar.set_description('[Training] loss: ' + \\\n",
    "                            f'{run_loss / run_size:.4f}, accuracy: ' + \\\n",
    "                            f'{corr / run_size:.4f}')\n",
    "        \n",
    "    acc = corr / len(data_loader.dataset)\n",
    "\n",
    "    return run_loss / len(data_loader.dataset), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#평가를 위한 구문 작성\n",
    "def model_evaluate(model, data_loader, loss_fn, processing_device):\n",
    "    model.eval() #모델을 평가 모드로 전환\n",
    "\n",
    "    #gradient업데이틀를 방지해주자\n",
    "    with torch.no_grad():\n",
    "\n",
    "        #여기서도 loss, accuracy 계산을 위한 임시 변수 선언\n",
    "        run_loss, corr = 0, 0\n",
    "\n",
    "\n",
    "        for image, label in data_loader: #이때 사용되는 데이터는 평가용 데이터\n",
    "            #입력된 데이터를 먼저 GPU로 이전하기\n",
    "            image = image.to(processing_device)\n",
    "            label = label.to(processing_device)\n",
    "\n",
    "\n",
    "            #평가 결과를 도출하자\n",
    "            outputs = model(image) #평가모드는 1개만 출력이 나오나보네...\n",
    "\n",
    "            _, pred = outputs.max(dim=1)\n",
    "\n",
    "            \n",
    "            #모델의 평가 결과 도출 부분\n",
    "            # 배치의 실제 크기에 맞추어 정확도와 손실을 계산\n",
    "            corr += torch.sum(pred.eq(label)).item()\n",
    "            run_loss += loss_fn(outputs, label).item() * image.size(0)\n",
    "\n",
    "        # 전체 데이터셋에 대한 평균 손실과 정확도 계산\n",
    "        acc = corr / len(data_loader.dataset)\n",
    "\n",
    "        return run_loss / len(data_loader.dataset), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1042 [00:00<?, ?it/s]c:\\Users\\Z13_ASH\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "c:\\Users\\Z13_ASH\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\functional.py:1374: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n",
      "[Training] loss: 3.6330, accuracy: 0.1362: 100%|██████████| 1042/1042 [02:10<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from inf to 3.26544. Saving Model!\n",
      "epoch 01, loss: 3.63296, acc: 0.13622, val_loss: 3.26544, val_accuracy: 0.19810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 2.7543, accuracy: 0.2873: 100%|██████████| 1042/1042 [02:11<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 3.26544 to 2.40563. Saving Model!\n",
      "epoch 02, loss: 2.75427, acc: 0.28726, val_loss: 2.40563, val_accuracy: 0.36570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 2.1960, accuracy: 0.4040: 100%|██████████| 1042/1042 [02:10<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 2.40563 to 2.07830. Saving Model!\n",
      "epoch 03, loss: 2.19598, acc: 0.40396, val_loss: 2.07830, val_accuracy: 0.43570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.8665, accuracy: 0.4808: 100%|██████████| 1042/1042 [02:09<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 2.07830 to 1.69220. Saving Model!\n",
      "epoch 04, loss: 1.86649, acc: 0.48076, val_loss: 1.69220, val_accuracy: 0.52250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.6376, accuracy: 0.5345: 100%|██████████| 1042/1042 [02:10<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 05, loss: 1.63762, acc: 0.53446, val_loss: 1.70276, val_accuracy: 0.52110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.4670, accuracy: 0.5789: 100%|██████████| 1042/1042 [02:10<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.69220 to 1.55934. Saving Model!\n",
      "epoch 06, loss: 1.46695, acc: 0.57894, val_loss: 1.55934, val_accuracy: 0.55720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.3265, accuracy: 0.6141: 100%|██████████| 1042/1042 [02:10<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.55934 to 1.43959. Saving Model!\n",
      "epoch 07, loss: 1.32654, acc: 0.61406, val_loss: 1.43959, val_accuracy: 0.59070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.2034, accuracy: 0.6458: 100%|██████████| 1042/1042 [02:10<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.43959 to 1.39917. Saving Model!\n",
      "epoch 08, loss: 1.20340, acc: 0.64578, val_loss: 1.39917, val_accuracy: 0.60740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.0969, accuracy: 0.6758: 100%|██████████| 1042/1042 [02:10<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.39917 to 1.38269. Saving Model!\n",
      "epoch 09, loss: 1.09689, acc: 0.67578, val_loss: 1.38269, val_accuracy: 0.61370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.0003, accuracy: 0.7000: 100%|██████████| 1042/1042 [02:10<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.38269 to 1.34976. Saving Model!\n",
      "epoch 10, loss: 1.00026, acc: 0.69998, val_loss: 1.34976, val_accuracy: 0.62080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.9158, accuracy: 0.7223: 100%|██████████| 1042/1042 [02:10<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.34976 to 1.30372. Saving Model!\n",
      "epoch 11, loss: 0.91577, acc: 0.72226, val_loss: 1.30372, val_accuracy: 0.63870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.8396, accuracy: 0.7400: 100%|██████████| 1042/1042 [02:10<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, loss: 0.83959, acc: 0.73996, val_loss: 1.31593, val_accuracy: 0.64020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.7585, accuracy: 0.7673: 100%|██████████| 1042/1042 [02:10<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, loss: 0.75854, acc: 0.76734, val_loss: 1.39192, val_accuracy: 0.63480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.6956, accuracy: 0.7844: 100%|██████████| 1042/1042 [02:10<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.30372 to 1.25536. Saving Model!\n",
      "epoch 14, loss: 0.69563, acc: 0.78444, val_loss: 1.25536, val_accuracy: 0.65640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.6331, accuracy: 0.7992: 100%|██████████| 1042/1042 [02:10<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, loss: 0.63312, acc: 0.79922, val_loss: 1.29875, val_accuracy: 0.65550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.5766, accuracy: 0.8185: 100%|██████████| 1042/1042 [02:10<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, loss: 0.57663, acc: 0.81854, val_loss: 1.42388, val_accuracy: 0.65180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.5267, accuracy: 0.8311: 100%|██████████| 1042/1042 [02:10<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, loss: 0.52673, acc: 0.83108, val_loss: 1.31277, val_accuracy: 0.66600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4812, accuracy: 0.8456: 100%|██████████| 1042/1042 [02:10<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, loss: 0.48125, acc: 0.84558, val_loss: 1.31004, val_accuracy: 0.67030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4325, accuracy: 0.8609: 100%|██████████| 1042/1042 [02:11<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, loss: 0.43253, acc: 0.86094, val_loss: 1.36941, val_accuracy: 0.66040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4044, accuracy: 0.8697: 100%|██████████| 1042/1042 [02:11<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, loss: 0.40442, acc: 0.86972, val_loss: 1.37838, val_accuracy: 0.66730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.3689, accuracy: 0.8796: 100%|██████████| 1042/1042 [02:10<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, loss: 0.36886, acc: 0.87964, val_loss: 1.35765, val_accuracy: 0.67170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.3362, accuracy: 0.8909: 100%|██████████| 1042/1042 [02:11<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, loss: 0.33618, acc: 0.89088, val_loss: 1.41776, val_accuracy: 0.66010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.3163, accuracy: 0.8967: 100%|██████████| 1042/1042 [02:10<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, loss: 0.31632, acc: 0.89672, val_loss: 1.49225, val_accuracy: 0.66570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.3009, accuracy: 0.9010: 100%|██████████| 1042/1042 [02:11<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, loss: 0.30094, acc: 0.90098, val_loss: 1.52317, val_accuracy: 0.66250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.2735, accuracy: 0.9098: 100%|██████████| 1042/1042 [02:11<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, loss: 0.27353, acc: 0.90976, val_loss: 1.45606, val_accuracy: 0.66930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.2618, accuracy: 0.9145: 100%|██████████| 1042/1042 [02:10<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, loss: 0.26180, acc: 0.91454, val_loss: 1.49832, val_accuracy: 0.66570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.2370, accuracy: 0.9202: 100%|██████████| 1042/1042 [02:10<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, loss: 0.23703, acc: 0.92016, val_loss: 1.57354, val_accuracy: 0.66720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.2285, accuracy: 0.9240: 100%|██████████| 1042/1042 [02:10<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, loss: 0.22846, acc: 0.92396, val_loss: 1.56292, val_accuracy: 0.67150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.2232, accuracy: 0.9258: 100%|██████████| 1042/1042 [02:10<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, loss: 0.22323, acc: 0.92582, val_loss: 1.61581, val_accuracy: 0.66220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.2016, accuracy: 0.9328: 100%|██████████| 1042/1042 [02:10<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, loss: 0.20163, acc: 0.93278, val_loss: 1.67960, val_accuracy: 0.66830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.2012, accuracy: 0.9326: 100%|██████████| 1042/1042 [02:10<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, loss: 0.20118, acc: 0.93260, val_loss: 1.59873, val_accuracy: 0.67330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1881, accuracy: 0.9376: 100%|██████████| 1042/1042 [02:10<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, loss: 0.18811, acc: 0.93760, val_loss: 1.62950, val_accuracy: 0.67320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1873, accuracy: 0.9384: 100%|██████████| 1042/1042 [02:10<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, loss: 0.18734, acc: 0.93836, val_loss: 1.65881, val_accuracy: 0.67120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1662, accuracy: 0.9448: 100%|██████████| 1042/1042 [02:11<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, loss: 0.16620, acc: 0.94478, val_loss: 1.76789, val_accuracy: 0.65980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1736, accuracy: 0.9422: 100%|██████████| 1042/1042 [02:11<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, loss: 0.17361, acc: 0.94222, val_loss: 1.60159, val_accuracy: 0.68570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1660, accuracy: 0.9440: 100%|██████████| 1042/1042 [02:11<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, loss: 0.16597, acc: 0.94400, val_loss: 1.65706, val_accuracy: 0.67900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1612, accuracy: 0.9476: 100%|██████████| 1042/1042 [02:10<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, loss: 0.16119, acc: 0.94758, val_loss: 1.72320, val_accuracy: 0.67230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1509, accuracy: 0.9506: 100%|██████████| 1042/1042 [02:14<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, loss: 0.15093, acc: 0.95064, val_loss: 1.78266, val_accuracy: 0.66410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1491, accuracy: 0.9515: 100%|██████████| 1042/1042 [02:19<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, loss: 0.14910, acc: 0.95150, val_loss: 1.74426, val_accuracy: 0.67370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1428, accuracy: 0.9526: 100%|██████████| 1042/1042 [02:12<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, loss: 0.14280, acc: 0.95256, val_loss: 1.77021, val_accuracy: 0.66650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1455, accuracy: 0.9520: 100%|██████████| 1042/1042 [02:10<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, loss: 0.14551, acc: 0.95196, val_loss: 1.73453, val_accuracy: 0.68100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1290, accuracy: 0.9570: 100%|██████████| 1042/1042 [02:10<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, loss: 0.12903, acc: 0.95702, val_loss: 1.77935, val_accuracy: 0.67560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1331, accuracy: 0.9557: 100%|██████████| 1042/1042 [02:11<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, loss: 0.13307, acc: 0.95568, val_loss: 1.71357, val_accuracy: 0.68400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1377, accuracy: 0.9538: 100%|██████████| 1042/1042 [02:10<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, loss: 0.13770, acc: 0.95382, val_loss: 1.90189, val_accuracy: 0.66320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1172, accuracy: 0.9614: 100%|██████████| 1042/1042 [02:10<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, loss: 0.11721, acc: 0.96138, val_loss: 1.85666, val_accuracy: 0.67330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1232, accuracy: 0.9594: 100%|██████████| 1042/1042 [02:10<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, loss: 0.12315, acc: 0.95944, val_loss: 1.78599, val_accuracy: 0.67590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1175, accuracy: 0.9605: 100%|██████████| 1042/1042 [02:10<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, loss: 0.11748, acc: 0.96050, val_loss: 1.88496, val_accuracy: 0.66940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1174, accuracy: 0.9609: 100%|██████████| 1042/1042 [02:10<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, loss: 0.11736, acc: 0.96088, val_loss: 1.81617, val_accuracy: 0.68140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1145, accuracy: 0.9614: 100%|██████████| 1042/1042 [02:11<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, loss: 0.11447, acc: 0.96136, val_loss: 1.80243, val_accuracy: 0.68470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1151, accuracy: 0.9614: 100%|██████████| 1042/1042 [02:10<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, loss: 0.11509, acc: 0.96138, val_loss: 1.81595, val_accuracy: 0.67920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1094, accuracy: 0.9633: 100%|██████████| 1042/1042 [02:09<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51, loss: 0.10940, acc: 0.96334, val_loss: 1.90888, val_accuracy: 0.67190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1028, accuracy: 0.9661: 100%|██████████| 1042/1042 [02:10<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52, loss: 0.10279, acc: 0.96612, val_loss: 1.92875, val_accuracy: 0.67160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0993, accuracy: 0.9666: 100%|██████████| 1042/1042 [02:10<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53, loss: 0.09934, acc: 0.96660, val_loss: 1.86661, val_accuracy: 0.68180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1070, accuracy: 0.9656: 100%|██████████| 1042/1042 [02:10<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54, loss: 0.10696, acc: 0.96564, val_loss: 1.89802, val_accuracy: 0.67500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1028, accuracy: 0.9653: 100%|██████████| 1042/1042 [02:10<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55, loss: 0.10281, acc: 0.96530, val_loss: 1.80047, val_accuracy: 0.68880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0989, accuracy: 0.9666: 100%|██████████| 1042/1042 [02:10<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56, loss: 0.09891, acc: 0.96660, val_loss: 1.95283, val_accuracy: 0.67930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0984, accuracy: 0.9674: 100%|██████████| 1042/1042 [02:10<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57, loss: 0.09842, acc: 0.96740, val_loss: 1.85726, val_accuracy: 0.68470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.1012, accuracy: 0.9670: 100%|██████████| 1042/1042 [02:10<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58, loss: 0.10116, acc: 0.96698, val_loss: 1.88529, val_accuracy: 0.69030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0900, accuracy: 0.9690: 100%|██████████| 1042/1042 [02:10<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59, loss: 0.09000, acc: 0.96902, val_loss: 1.96354, val_accuracy: 0.67840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0926, accuracy: 0.9698: 100%|██████████| 1042/1042 [02:10<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60, loss: 0.09260, acc: 0.96978, val_loss: 1.87276, val_accuracy: 0.68590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0946, accuracy: 0.9687: 100%|██████████| 1042/1042 [02:11<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61, loss: 0.09463, acc: 0.96868, val_loss: 1.90453, val_accuracy: 0.68780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0929, accuracy: 0.9693: 100%|██████████| 1042/1042 [02:11<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62, loss: 0.09293, acc: 0.96930, val_loss: 1.92314, val_accuracy: 0.67990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0884, accuracy: 0.9700: 100%|██████████| 1042/1042 [02:10<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63, loss: 0.08840, acc: 0.97002, val_loss: 1.90486, val_accuracy: 0.68840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0879, accuracy: 0.9710: 100%|██████████| 1042/1042 [02:11<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64, loss: 0.08789, acc: 0.97102, val_loss: 1.86346, val_accuracy: 0.68950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0858, accuracy: 0.9722: 100%|██████████| 1042/1042 [02:10<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65, loss: 0.08581, acc: 0.97218, val_loss: 1.98072, val_accuracy: 0.67950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0860, accuracy: 0.9717: 100%|██████████| 1042/1042 [02:10<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66, loss: 0.08603, acc: 0.97174, val_loss: 1.99701, val_accuracy: 0.68120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0780, accuracy: 0.9734: 100%|██████████| 1042/1042 [02:10<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67, loss: 0.07805, acc: 0.97338, val_loss: 1.97422, val_accuracy: 0.68350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0885, accuracy: 0.9706: 100%|██████████| 1042/1042 [02:10<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68, loss: 0.08846, acc: 0.97062, val_loss: 1.97156, val_accuracy: 0.68640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0759, accuracy: 0.9743: 100%|██████████| 1042/1042 [02:10<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69, loss: 0.07592, acc: 0.97434, val_loss: 1.88625, val_accuracy: 0.68990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0803, accuracy: 0.9735: 100%|██████████| 1042/1042 [02:11<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70, loss: 0.08026, acc: 0.97352, val_loss: 2.03336, val_accuracy: 0.68560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0862, accuracy: 0.9717: 100%|██████████| 1042/1042 [02:10<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71, loss: 0.08617, acc: 0.97172, val_loss: 1.94462, val_accuracy: 0.69200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0795, accuracy: 0.9740: 100%|██████████| 1042/1042 [02:10<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72, loss: 0.07947, acc: 0.97400, val_loss: 2.05266, val_accuracy: 0.67870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0726, accuracy: 0.9764: 100%|██████████| 1042/1042 [02:15<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73, loss: 0.07259, acc: 0.97642, val_loss: 2.00739, val_accuracy: 0.67980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0725, accuracy: 0.9761: 100%|██████████| 1042/1042 [02:13<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74, loss: 0.07246, acc: 0.97606, val_loss: 1.98184, val_accuracy: 0.68470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0754, accuracy: 0.9753: 100%|██████████| 1042/1042 [02:10<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75, loss: 0.07537, acc: 0.97526, val_loss: 1.99735, val_accuracy: 0.68510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0731, accuracy: 0.9758: 100%|██████████| 1042/1042 [02:10<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76, loss: 0.07314, acc: 0.97576, val_loss: 1.95536, val_accuracy: 0.68670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0748, accuracy: 0.9758: 100%|██████████| 1042/1042 [02:11<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77, loss: 0.07483, acc: 0.97582, val_loss: 2.05731, val_accuracy: 0.67600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0670, accuracy: 0.9784: 100%|██████████| 1042/1042 [02:20<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78, loss: 0.06696, acc: 0.97836, val_loss: 2.04119, val_accuracy: 0.68220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0772, accuracy: 0.9748: 100%|██████████| 1042/1042 [02:12<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79, loss: 0.07722, acc: 0.97484, val_loss: 2.09004, val_accuracy: 0.67560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0689, accuracy: 0.9779: 100%|██████████| 1042/1042 [02:10<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80, loss: 0.06895, acc: 0.97788, val_loss: 2.02983, val_accuracy: 0.68620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0709, accuracy: 0.9762: 100%|██████████| 1042/1042 [02:11<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81, loss: 0.07090, acc: 0.97620, val_loss: 2.05970, val_accuracy: 0.68520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0664, accuracy: 0.9786: 100%|██████████| 1042/1042 [02:11<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82, loss: 0.06645, acc: 0.97858, val_loss: 2.04373, val_accuracy: 0.67980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0691, accuracy: 0.9769: 100%|██████████| 1042/1042 [02:11<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83, loss: 0.06912, acc: 0.97688, val_loss: 2.14423, val_accuracy: 0.68020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0669, accuracy: 0.9782: 100%|██████████| 1042/1042 [02:11<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84, loss: 0.06694, acc: 0.97822, val_loss: 2.06916, val_accuracy: 0.68130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0679, accuracy: 0.9777: 100%|██████████| 1042/1042 [02:11<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85, loss: 0.06790, acc: 0.97768, val_loss: 2.03278, val_accuracy: 0.68610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0698, accuracy: 0.9779: 100%|██████████| 1042/1042 [02:11<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86, loss: 0.06982, acc: 0.97786, val_loss: 2.09381, val_accuracy: 0.68290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0648, accuracy: 0.9793: 100%|██████████| 1042/1042 [02:10<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87, loss: 0.06483, acc: 0.97932, val_loss: 2.02501, val_accuracy: 0.68380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0626, accuracy: 0.9794: 100%|██████████| 1042/1042 [02:10<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88, loss: 0.06257, acc: 0.97940, val_loss: 2.07721, val_accuracy: 0.68310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0689, accuracy: 0.9775: 100%|██████████| 1042/1042 [02:11<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89, loss: 0.06889, acc: 0.97748, val_loss: 2.11882, val_accuracy: 0.68210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0636, accuracy: 0.9785: 100%|██████████| 1042/1042 [02:11<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90, loss: 0.06363, acc: 0.97854, val_loss: 2.11914, val_accuracy: 0.68350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0595, accuracy: 0.9804: 100%|██████████| 1042/1042 [02:11<00:00,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91, loss: 0.05951, acc: 0.98040, val_loss: 2.02002, val_accuracy: 0.69540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0641, accuracy: 0.9792: 100%|██████████| 1042/1042 [02:10<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92, loss: 0.06411, acc: 0.97922, val_loss: 2.15613, val_accuracy: 0.67550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0590, accuracy: 0.9812: 100%|██████████| 1042/1042 [02:10<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93, loss: 0.05895, acc: 0.98122, val_loss: 2.10506, val_accuracy: 0.68900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0670, accuracy: 0.9789: 100%|██████████| 1042/1042 [02:11<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94, loss: 0.06698, acc: 0.97888, val_loss: 2.00633, val_accuracy: 0.68850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0573, accuracy: 0.9814: 100%|██████████| 1042/1042 [02:11<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95, loss: 0.05729, acc: 0.98136, val_loss: 2.15437, val_accuracy: 0.67860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0584, accuracy: 0.9816: 100%|██████████| 1042/1042 [02:11<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96, loss: 0.05836, acc: 0.98156, val_loss: 2.08898, val_accuracy: 0.69180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0596, accuracy: 0.9805: 100%|██████████| 1042/1042 [02:11<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97, loss: 0.05965, acc: 0.98052, val_loss: 2.18004, val_accuracy: 0.68340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0497, accuracy: 0.9840: 100%|██████████| 1042/1042 [02:11<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98, loss: 0.04971, acc: 0.98396, val_loss: 2.05051, val_accuracy: 0.68960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0612, accuracy: 0.9802: 100%|██████████| 1042/1042 [02:10<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99, loss: 0.06117, acc: 0.98016, val_loss: 2.05720, val_accuracy: 0.69200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.0553, accuracy: 0.9820: 100%|██████████| 1042/1042 [02:12<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100, loss: 0.05534, acc: 0.98198, val_loss: 2.10171, val_accuracy: 0.69350\n"
     ]
    }
   ],
   "source": [
    "min_loss = np.inf\n",
    "MODEL_NAME = 'GoogLeNet'\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    # Model Training\n",
    "    # 훈련 손실과 정확도를 반환 받습니다.\n",
    "    train_loss, train_acc = model_train(ex_model, train_loader, criterion, optimizer, device)\n",
    "\n",
    "    # 검증 손실과 검증 정확도를 반환 받습니다.\n",
    "    val_loss, val_acc = model_evaluate(ex_model, test_loader, criterion, device)   \n",
    "    \n",
    "    # val_loss 가 개선되었다면 min_loss를 갱신하고 model의 가중치(weights)를 저장합니다.\n",
    "    if val_loss < min_loss:\n",
    "        print(f'[INFO] val_loss has been improved from '\n",
    "            f'{min_loss:.5f} to {val_loss:.5f}. Saving Model!')\n",
    "        min_loss = val_loss\n",
    "        torch.save(ex_model.state_dict(), f'{MODEL_NAME}.pth')\n",
    "    \n",
    "    # Epoch 별 결과를 출력합니다.\n",
    "    print(f'epoch {epoch+1:02d}, loss: {train_loss:.5f}, acc: {train_acc:.5f}, '\n",
    "        f'val_loss: {val_loss:.5f}, val_accuracy: {val_acc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation loss: 1.25536, evaluation accuracy: 0.65640\n"
     ]
    }
   ],
   "source": [
    "ex_model.load_state_dict(torch.load(f'{MODEL_NAME}.pth'))\n",
    "\n",
    "final_loss, final_acc = model_evaluate(ex_model, test_loader, criterion, device)\n",
    "print(f'evaluation loss: {final_loss:.5f}, evaluation accuracy: {final_acc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 보조분류기 있는 GoogLeNet 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GoogLeNet_withAux(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (3): LocalResponseNorm(2, alpha=0.0001, beta=0.75, k=1.0)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): LocalResponseNorm(2, alpha=0.0001, beta=0.75, k=1.0)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (inception_3a): Inception_module(\n",
       "    (conv1x1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv3x3): Sequential(\n",
       "      (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv5x5): Sequential(\n",
       "      (0): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool_net): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (inception_3b): Inception_module(\n",
       "    (conv1x1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv3x3): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv5x5): Sequential(\n",
       "      (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool_net): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (maxpool_3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (inception_4a): Inception_module(\n",
       "    (conv1x1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv3x3): Sequential(\n",
       "      (0): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv5x5): Sequential(\n",
       "      (0): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool_net): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (aux1): AuxModule(\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(4, 4))\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout2d(p=0.7, inplace=False)\n",
       "      (3): Linear(in_features=1024, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (inception_4b): Inception_module(\n",
       "    (conv1x1): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv3x3): Sequential(\n",
       "      (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv5x5): Sequential(\n",
       "      (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool_net): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (inception_4c): Inception_module(\n",
       "    (conv1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv3x3): Sequential(\n",
       "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv5x5): Sequential(\n",
       "      (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool_net): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (inception_4d): Inception_module(\n",
       "    (conv1x1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv3x3): Sequential(\n",
       "      (0): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv5x5): Sequential(\n",
       "      (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool_net): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (aux2): AuxModule(\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(4, 4))\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout2d(p=0.7, inplace=False)\n",
       "      (3): Linear(in_features=1024, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (inception_4e): Inception_module(\n",
       "    (conv1x1): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv3x3): Sequential(\n",
       "      (0): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv5x5): Sequential(\n",
       "      (0): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool_net): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (maxpool_4): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (inception_5a): Inception_module(\n",
       "    (conv1x1): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv3x3): Sequential(\n",
       "      (0): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv5x5): Sequential(\n",
       "      (0): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool_net): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (inception_5b): Inception_module(\n",
       "    (conv1x1): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv3x3): Sequential(\n",
       "      (0): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv5x5): Sequential(\n",
       "      (0): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool_net): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout2d(p=0.4, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_model_1 = GoogLeNet_withAux(in_channels=3, num_classes=train_label_count)\n",
    "ex_model_1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0002\n",
    "\n",
    "import torch.nn.functional as F #이거는 활성화 함수 모듈\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion_1 = nn.CrossEntropyLoss()\n",
    "optimizer_1 = optim.Adam(ex_model_1.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm #훈련 진행상황 체크\n",
    "\n",
    "def model_train_withAux(model, data_loader, loss_fn, optimizer_fn, processing_device):\n",
    "\n",
    "    model.train() #모델을 훈련 모드로 설정\n",
    "\n",
    "    #loss와 accuracy를 계산하기 위한 임시 변수를 생성\n",
    "    run_size, run_loss, corr = 0, 0, 0\n",
    "\n",
    "    progress_bar = tqdm(data_loader) #이때 사용되는 데이터는 훈련용 데이터\n",
    "\n",
    "\n",
    "    for batch_idx, (image, label) in enumerate(progress_bar, start=1):\n",
    "        #입력된 데이터를 먼저 GPU로 이전하기\n",
    "        image = image.to(processing_device)\n",
    "        label = label.to(processing_device)\n",
    "\n",
    "        #전사과정 수행\n",
    "        pred0, pred1, pred2 = model(image) #출력이 3개 나온다.\n",
    "\n",
    "        loss_0 = loss_fn(pred0, label)\n",
    "        loss_1 = loss_fn(pred1, label)\n",
    "        loss_2 = loss_fn(pred2, label) #출력별 loos중간결과값을 계산함\n",
    "        \n",
    "        loss = loss_0 + 0.3*(loss_1 + loss_2)\n",
    "\n",
    "        #옵티마이저의 Gradient 초기화\n",
    "        optimizer_fn.zero_grad()\n",
    "\n",
    "        #backward 과정 수행\n",
    "        loss.backward() #Backprogration을 진행하여 Gradient계산\n",
    "        optimizer_fn.step() #계산된 gradient(모델 파라미터)를 업데이트\n",
    "\n",
    "\n",
    "        #여기부터는 학습이 잘 되고 있는지 확인하는 부분\n",
    "        _, pred = pred0.max(dim=1)\n",
    "        corr += pred.eq(label).sum().item()\n",
    "        \n",
    "        run_loss += loss.item() * image.size(0)\n",
    "        run_size += image.size(0)\n",
    "        progress_bar.set_description('[Training] loss: ' + \\\n",
    "                            f'{run_loss / run_size:.4f}, accuracy: ' + \\\n",
    "                            f'{corr / run_size:.4f}')\n",
    "        \n",
    "    acc = corr / len(data_loader.dataset)\n",
    "\n",
    "    return run_loss / len(data_loader.dataset), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#평가를 위한 구문 작성\n",
    "def model_evaluate_withAux(model, data_loader, loss_fn, processing_device):\n",
    "    model.eval() #모델을 평가 모드로 전환\n",
    "\n",
    "    #gradient업데이틀를 방지해주자\n",
    "    with torch.no_grad():\n",
    "\n",
    "        #여기서도 loss, accuracy 계산을 위한 임시 변수 선언\n",
    "        run_loss, corr = 0, 0\n",
    "\n",
    "\n",
    "        for image, label in data_loader: #이때 사용되는 데이터는 평가용 데이터\n",
    "            #입력된 데이터를 먼저 GPU로 이전하기\n",
    "            image = image.to(processing_device)\n",
    "            label = label.to(processing_device)\n",
    "\n",
    "\n",
    "            #평가 결과를 도출하자\n",
    "            outputs = model(image) #평가모드는 1개만 출력이 나오나보네...\n",
    "\n",
    "            _, pred = outputs.max(dim=1)\n",
    "\n",
    "            \n",
    "            #모델의 평가 결과 도출 부분\n",
    "            # 배치의 실제 크기에 맞추어 정확도와 손실을 계산\n",
    "            corr += torch.sum(pred.eq(label)).item()\n",
    "            run_loss += loss_fn(outputs, label).item() * image.size(0)\n",
    "\n",
    "        # 전체 데이터셋에 대한 평균 손실과 정확도 계산\n",
    "        acc = corr / len(data_loader.dataset)\n",
    "\n",
    "        return run_loss / len(data_loader.dataset), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 6.6673, accuracy: 0.0532: 100%|██████████| 1042/1042 [02:35<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from inf to 3.74917. Saving Model!\n",
      "epoch 01, loss: 6.66730, acc: 0.05322, val_loss: 3.74917, val_accuracy: 0.11400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 5.8225, accuracy: 0.1395: 100%|██████████| 1042/1042 [02:26<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 3.74917 to 3.38131. Saving Model!\n",
      "epoch 02, loss: 5.82252, acc: 0.13946, val_loss: 3.38131, val_accuracy: 0.18080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 5.2532, accuracy: 0.2072: 100%|██████████| 1042/1042 [02:30<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 3.38131 to 3.00168. Saving Model!\n",
      "epoch 03, loss: 5.25319, acc: 0.20720, val_loss: 3.00168, val_accuracy: 0.25150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 4.8161, accuracy: 0.2660: 100%|██████████| 1042/1042 [02:28<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 3.00168 to 2.73239. Saving Model!\n",
      "epoch 04, loss: 4.81605, acc: 0.26598, val_loss: 2.73239, val_accuracy: 0.30890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 4.4436, accuracy: 0.3194: 100%|██████████| 1042/1042 [02:26<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 2.73239 to 2.52418. Saving Model!\n",
      "epoch 05, loss: 4.44362, acc: 0.31936, val_loss: 2.52418, val_accuracy: 0.35400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 4.1399, accuracy: 0.3632: 100%|██████████| 1042/1042 [02:25<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 2.52418 to 2.31812. Saving Model!\n",
      "epoch 06, loss: 4.13985, acc: 0.36316, val_loss: 2.31812, val_accuracy: 0.39560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 3.8752, accuracy: 0.4091: 100%|██████████| 1042/1042 [02:25<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 2.31812 to 2.21032. Saving Model!\n",
      "epoch 07, loss: 3.87517, acc: 0.40908, val_loss: 2.21032, val_accuracy: 0.41980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 3.6504, accuracy: 0.4435: 100%|██████████| 1042/1042 [02:25<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 2.21032 to 2.04799. Saving Model!\n",
      "epoch 08, loss: 3.65036, acc: 0.44352, val_loss: 2.04799, val_accuracy: 0.45590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 3.4468, accuracy: 0.4772: 100%|██████████| 1042/1042 [02:28<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 2.04799 to 2.02540. Saving Model!\n",
      "epoch 09, loss: 3.44678, acc: 0.47716, val_loss: 2.02540, val_accuracy: 0.45720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 3.2590, accuracy: 0.5068: 100%|██████████| 1042/1042 [02:25<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 2.02540 to 1.93677. Saving Model!\n",
      "epoch 10, loss: 3.25897, acc: 0.50676, val_loss: 1.93677, val_accuracy: 0.48150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 3.0866, accuracy: 0.5325: 100%|██████████| 1042/1042 [02:25<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.93677 to 1.81832. Saving Model!\n",
      "epoch 11, loss: 3.08657, acc: 0.53250, val_loss: 1.81832, val_accuracy: 0.51020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 2.9200, accuracy: 0.5624: 100%|██████████| 1042/1042 [02:25<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.81832 to 1.80476. Saving Model!\n",
      "epoch 12, loss: 2.91996, acc: 0.56242, val_loss: 1.80476, val_accuracy: 0.51630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 2.7755, accuracy: 0.5848: 100%|██████████| 1042/1042 [02:26<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.80476 to 1.74345. Saving Model!\n",
      "epoch 13, loss: 2.77554, acc: 0.58476, val_loss: 1.74345, val_accuracy: 0.53080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 2.6362, accuracy: 0.6080: 100%|██████████| 1042/1042 [02:26<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.74345 to 1.71859. Saving Model!\n",
      "epoch 14, loss: 2.63621, acc: 0.60800, val_loss: 1.71859, val_accuracy: 0.53950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 2.4971, accuracy: 0.6337: 100%|██████████| 1042/1042 [02:26<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, loss: 2.49708, acc: 0.63370, val_loss: 1.72326, val_accuracy: 0.54920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 2.3781, accuracy: 0.6535: 100%|██████████| 1042/1042 [02:25<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.71859 to 1.69680. Saving Model!\n",
      "epoch 16, loss: 2.37810, acc: 0.65354, val_loss: 1.69680, val_accuracy: 0.55250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 2.2567, accuracy: 0.6745: 100%|██████████| 1042/1042 [02:26<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.69680 to 1.63855. Saving Model!\n",
      "epoch 17, loss: 2.25674, acc: 0.67450, val_loss: 1.63855, val_accuracy: 0.56660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 2.1433, accuracy: 0.6987: 100%|██████████| 1042/1042 [02:25<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, loss: 2.14332, acc: 0.69868, val_loss: 1.69352, val_accuracy: 0.56340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 2.0340, accuracy: 0.7172: 100%|██████████| 1042/1042 [02:25<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, loss: 2.03399, acc: 0.71722, val_loss: 1.78330, val_accuracy: 0.56390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.9269, accuracy: 0.7383: 100%|██████████| 1042/1042 [02:30<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, loss: 1.92688, acc: 0.73828, val_loss: 1.74600, val_accuracy: 0.56620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.8453, accuracy: 0.7520: 100%|██████████| 1042/1042 [02:25<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, loss: 1.84534, acc: 0.75200, val_loss: 1.70922, val_accuracy: 0.57730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.7524, accuracy: 0.7734: 100%|██████████| 1042/1042 [02:25<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, loss: 1.75236, acc: 0.77338, val_loss: 1.79052, val_accuracy: 0.56920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.6636, accuracy: 0.7906: 100%|██████████| 1042/1042 [02:25<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, loss: 1.66360, acc: 0.79060, val_loss: 1.86792, val_accuracy: 0.57000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.5882, accuracy: 0.8069: 100%|██████████| 1042/1042 [02:25<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, loss: 1.58823, acc: 0.80692, val_loss: 1.81284, val_accuracy: 0.57960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.5225, accuracy: 0.8201: 100%|██████████| 1042/1042 [02:25<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, loss: 1.52252, acc: 0.82014, val_loss: 1.84787, val_accuracy: 0.57710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.4485, accuracy: 0.8338: 100%|██████████| 1042/1042 [02:25<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, loss: 1.44845, acc: 0.83382, val_loss: 2.00195, val_accuracy: 0.56310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.3859, accuracy: 0.8453: 100%|██████████| 1042/1042 [02:25<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, loss: 1.38587, acc: 0.84526, val_loss: 2.01504, val_accuracy: 0.57900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.3407, accuracy: 0.8521: 100%|██████████| 1042/1042 [02:25<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, loss: 1.34070, acc: 0.85214, val_loss: 2.02623, val_accuracy: 0.56800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.2830, accuracy: 0.8663: 100%|██████████| 1042/1042 [02:25<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, loss: 1.28299, acc: 0.86630, val_loss: 2.13396, val_accuracy: 0.57630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.2366, accuracy: 0.8745: 100%|██████████| 1042/1042 [02:25<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, loss: 1.23664, acc: 0.87448, val_loss: 2.13032, val_accuracy: 0.57040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.2015, accuracy: 0.8824: 100%|██████████| 1042/1042 [02:25<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, loss: 1.20154, acc: 0.88236, val_loss: 2.18954, val_accuracy: 0.57140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.1519, accuracy: 0.8914: 100%|██████████| 1042/1042 [02:25<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, loss: 1.15186, acc: 0.89144, val_loss: 2.16012, val_accuracy: 0.57250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.1212, accuracy: 0.8956: 100%|██████████| 1042/1042 [02:25<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, loss: 1.12121, acc: 0.89556, val_loss: 2.27355, val_accuracy: 0.57550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.0832, accuracy: 0.9022: 100%|██████████| 1042/1042 [02:25<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, loss: 1.08319, acc: 0.90220, val_loss: 2.31132, val_accuracy: 0.57740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.0555, accuracy: 0.9075: 100%|██████████| 1042/1042 [02:25<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, loss: 1.05549, acc: 0.90748, val_loss: 2.31093, val_accuracy: 0.57900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.0291, accuracy: 0.9112: 100%|██████████| 1042/1042 [02:25<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, loss: 1.02907, acc: 0.91122, val_loss: 2.45478, val_accuracy: 0.58100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.0040, accuracy: 0.9159: 100%|██████████| 1042/1042 [02:25<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, loss: 1.00397, acc: 0.91588, val_loss: 2.32365, val_accuracy: 0.57680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.9751, accuracy: 0.9204: 100%|██████████| 1042/1042 [02:25<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, loss: 0.97513, acc: 0.92040, val_loss: 2.36313, val_accuracy: 0.58580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.9399, accuracy: 0.9257: 100%|██████████| 1042/1042 [02:25<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, loss: 0.93986, acc: 0.92568, val_loss: 2.47651, val_accuracy: 0.58300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.9349, accuracy: 0.9234: 100%|██████████| 1042/1042 [02:25<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, loss: 0.93487, acc: 0.92344, val_loss: 2.49467, val_accuracy: 0.56750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.9109, accuracy: 0.9278: 100%|██████████| 1042/1042 [02:25<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, loss: 0.91088, acc: 0.92784, val_loss: 2.52708, val_accuracy: 0.57910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.8860, accuracy: 0.9320: 100%|██████████| 1042/1042 [02:24<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, loss: 0.88602, acc: 0.93200, val_loss: 2.63432, val_accuracy: 0.57980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.8674, accuracy: 0.9360: 100%|██████████| 1042/1042 [02:25<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, loss: 0.86742, acc: 0.93602, val_loss: 2.58836, val_accuracy: 0.58730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.8529, accuracy: 0.9359: 100%|██████████| 1042/1042 [02:25<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, loss: 0.85291, acc: 0.93588, val_loss: 2.53438, val_accuracy: 0.58120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.8294, accuracy: 0.9395: 100%|██████████| 1042/1042 [02:25<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, loss: 0.82935, acc: 0.93950, val_loss: 2.63164, val_accuracy: 0.58340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.8210, accuracy: 0.9407: 100%|██████████| 1042/1042 [02:25<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, loss: 0.82096, acc: 0.94066, val_loss: 2.69886, val_accuracy: 0.57820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.8076, accuracy: 0.9435: 100%|██████████| 1042/1042 [02:25<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, loss: 0.80758, acc: 0.94348, val_loss: 2.67825, val_accuracy: 0.58500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.7885, accuracy: 0.9434: 100%|██████████| 1042/1042 [02:28<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, loss: 0.78845, acc: 0.94336, val_loss: 2.58109, val_accuracy: 0.58240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.7744, accuracy: 0.9463: 100%|██████████| 1042/1042 [02:25<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, loss: 0.77441, acc: 0.94628, val_loss: 2.75247, val_accuracy: 0.57930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.7683, accuracy: 0.9457: 100%|██████████| 1042/1042 [02:39<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, loss: 0.76831, acc: 0.94572, val_loss: 2.83817, val_accuracy: 0.58400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.7413, accuracy: 0.9523: 100%|██████████| 1042/1042 [03:15<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51, loss: 0.74130, acc: 0.95234, val_loss: 2.94345, val_accuracy: 0.57200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.7361, accuracy: 0.9491: 100%|██████████| 1042/1042 [03:07<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52, loss: 0.73614, acc: 0.94908, val_loss: 2.79181, val_accuracy: 0.58580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.7185, accuracy: 0.9514: 100%|██████████| 1042/1042 [03:09<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53, loss: 0.71849, acc: 0.95138, val_loss: 2.78737, val_accuracy: 0.59210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.7104, accuracy: 0.9519: 100%|██████████| 1042/1042 [03:08<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54, loss: 0.71042, acc: 0.95188, val_loss: 2.80281, val_accuracy: 0.58100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.6983, accuracy: 0.9514: 100%|██████████| 1042/1042 [03:08<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55, loss: 0.69834, acc: 0.95138, val_loss: 2.79292, val_accuracy: 0.58450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.6871, accuracy: 0.9545: 100%|██████████| 1042/1042 [03:13<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56, loss: 0.68711, acc: 0.95450, val_loss: 2.85151, val_accuracy: 0.59060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.6779, accuracy: 0.9546: 100%|██████████| 1042/1042 [03:10<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57, loss: 0.67787, acc: 0.95464, val_loss: 2.79363, val_accuracy: 0.58480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.6606, accuracy: 0.9566: 100%|██████████| 1042/1042 [03:09<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58, loss: 0.66056, acc: 0.95662, val_loss: 2.68868, val_accuracy: 0.58280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.6536, accuracy: 0.9576: 100%|██████████| 1042/1042 [03:08<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59, loss: 0.65364, acc: 0.95760, val_loss: 2.78278, val_accuracy: 0.58550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.6392, accuracy: 0.9596: 100%|██████████| 1042/1042 [03:13<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60, loss: 0.63919, acc: 0.95960, val_loss: 2.91090, val_accuracy: 0.58460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.6390, accuracy: 0.9577: 100%|██████████| 1042/1042 [03:09<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61, loss: 0.63900, acc: 0.95770, val_loss: 3.17790, val_accuracy: 0.57780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.6282, accuracy: 0.9598: 100%|██████████| 1042/1042 [03:08<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62, loss: 0.62819, acc: 0.95978, val_loss: 2.98515, val_accuracy: 0.58760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.6190, accuracy: 0.9601: 100%|██████████| 1042/1042 [03:08<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63, loss: 0.61904, acc: 0.96014, val_loss: 3.06292, val_accuracy: 0.58340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.6165, accuracy: 0.9606: 100%|██████████| 1042/1042 [03:05<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64, loss: 0.61646, acc: 0.96062, val_loss: 2.87792, val_accuracy: 0.59040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.6001, accuracy: 0.9625: 100%|██████████| 1042/1042 [03:14<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65, loss: 0.60006, acc: 0.96254, val_loss: 3.02950, val_accuracy: 0.57810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.5903, accuracy: 0.9640: 100%|██████████| 1042/1042 [03:15<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66, loss: 0.59032, acc: 0.96398, val_loss: 3.01298, val_accuracy: 0.58660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.5894, accuracy: 0.9613: 100%|██████████| 1042/1042 [03:07<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67, loss: 0.58938, acc: 0.96126, val_loss: 2.92764, val_accuracy: 0.58690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.5781, accuracy: 0.9624: 100%|██████████| 1042/1042 [03:09<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68, loss: 0.57813, acc: 0.96242, val_loss: 3.05264, val_accuracy: 0.58840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.5734, accuracy: 0.9629: 100%|██████████| 1042/1042 [03:13<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69, loss: 0.57342, acc: 0.96286, val_loss: 3.09724, val_accuracy: 0.57640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.5505, accuracy: 0.9687: 100%|██████████| 1042/1042 [03:11<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70, loss: 0.55051, acc: 0.96874, val_loss: 3.07472, val_accuracy: 0.58570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.5608, accuracy: 0.9631: 100%|██████████| 1042/1042 [03:08<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71, loss: 0.56082, acc: 0.96308, val_loss: 3.21262, val_accuracy: 0.58170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.5463, accuracy: 0.9670: 100%|██████████| 1042/1042 [03:09<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72, loss: 0.54626, acc: 0.96698, val_loss: 3.24527, val_accuracy: 0.58850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.5480, accuracy: 0.9641: 100%|██████████| 1042/1042 [03:07<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73, loss: 0.54804, acc: 0.96412, val_loss: 2.96073, val_accuracy: 0.59140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.5262, accuracy: 0.9682: 100%|██████████| 1042/1042 [03:14<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74, loss: 0.52620, acc: 0.96824, val_loss: 3.25532, val_accuracy: 0.58100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.5302, accuracy: 0.9664: 100%|██████████| 1042/1042 [03:17<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75, loss: 0.53022, acc: 0.96644, val_loss: 3.14012, val_accuracy: 0.57840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.5182, accuracy: 0.9686: 100%|██████████| 1042/1042 [03:05<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76, loss: 0.51825, acc: 0.96860, val_loss: 3.07119, val_accuracy: 0.58640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.5163, accuracy: 0.9679: 100%|██████████| 1042/1042 [03:07<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77, loss: 0.51631, acc: 0.96794, val_loss: 3.23340, val_accuracy: 0.58870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.5152, accuracy: 0.9678: 100%|██████████| 1042/1042 [03:13<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78, loss: 0.51521, acc: 0.96778, val_loss: 3.16254, val_accuracy: 0.59010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4936, accuracy: 0.9718: 100%|██████████| 1042/1042 [03:15<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79, loss: 0.49356, acc: 0.97180, val_loss: 3.22639, val_accuracy: 0.59470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.5040, accuracy: 0.9689: 100%|██████████| 1042/1042 [03:03<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80, loss: 0.50396, acc: 0.96890, val_loss: 3.26315, val_accuracy: 0.58740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4916, accuracy: 0.9710: 100%|██████████| 1042/1042 [03:08<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81, loss: 0.49157, acc: 0.97100, val_loss: 3.35486, val_accuracy: 0.58980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4977, accuracy: 0.9684: 100%|██████████| 1042/1042 [03:07<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82, loss: 0.49774, acc: 0.96844, val_loss: 3.11867, val_accuracy: 0.58980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4884, accuracy: 0.9691: 100%|██████████| 1042/1042 [03:13<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83, loss: 0.48842, acc: 0.96906, val_loss: 3.35127, val_accuracy: 0.58370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4740, accuracy: 0.9713: 100%|██████████| 1042/1042 [03:13<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84, loss: 0.47404, acc: 0.97134, val_loss: 3.09351, val_accuracy: 0.58450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4707, accuracy: 0.9708: 100%|██████████| 1042/1042 [03:07<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85, loss: 0.47066, acc: 0.97082, val_loss: 3.37382, val_accuracy: 0.58540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4685, accuracy: 0.9709: 100%|██████████| 1042/1042 [03:10<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86, loss: 0.46845, acc: 0.97094, val_loss: 3.18918, val_accuracy: 0.58220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4543, accuracy: 0.9734: 100%|██████████| 1042/1042 [03:13<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87, loss: 0.45433, acc: 0.97336, val_loss: 3.14555, val_accuracy: 0.59240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4584, accuracy: 0.9712: 100%|██████████| 1042/1042 [03:06<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88, loss: 0.45844, acc: 0.97116, val_loss: 3.48878, val_accuracy: 0.59110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4543, accuracy: 0.9723: 100%|██████████| 1042/1042 [03:08<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89, loss: 0.45431, acc: 0.97234, val_loss: 3.37380, val_accuracy: 0.59290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4467, accuracy: 0.9733: 100%|██████████| 1042/1042 [03:05<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90, loss: 0.44668, acc: 0.97334, val_loss: 3.40134, val_accuracy: 0.59200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4477, accuracy: 0.9721: 100%|██████████| 1042/1042 [03:07<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91, loss: 0.44766, acc: 0.97212, val_loss: 3.37310, val_accuracy: 0.58700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4425, accuracy: 0.9725: 100%|██████████| 1042/1042 [03:13<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92, loss: 0.44247, acc: 0.97252, val_loss: 3.46287, val_accuracy: 0.57990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4435, accuracy: 0.9728: 100%|██████████| 1042/1042 [03:12<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93, loss: 0.44353, acc: 0.97278, val_loss: 3.03535, val_accuracy: 0.58890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4221, accuracy: 0.9746: 100%|██████████| 1042/1042 [03:08<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94, loss: 0.42206, acc: 0.97458, val_loss: 3.36484, val_accuracy: 0.58590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4260, accuracy: 0.9753: 100%|██████████| 1042/1042 [03:01<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95, loss: 0.42602, acc: 0.97528, val_loss: 3.49077, val_accuracy: 0.58680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4268, accuracy: 0.9733: 100%|██████████| 1042/1042 [03:13<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96, loss: 0.42681, acc: 0.97326, val_loss: 3.41851, val_accuracy: 0.58500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4061, accuracy: 0.9774: 100%|██████████| 1042/1042 [03:11<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97, loss: 0.40606, acc: 0.97742, val_loss: 3.34146, val_accuracy: 0.58870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4253, accuracy: 0.9721: 100%|██████████| 1042/1042 [03:09<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98, loss: 0.42532, acc: 0.97214, val_loss: 3.24920, val_accuracy: 0.59730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.4121, accuracy: 0.9741: 100%|██████████| 1042/1042 [03:07<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99, loss: 0.41213, acc: 0.97412, val_loss: 3.08959, val_accuracy: 0.60170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.3982, accuracy: 0.9771: 100%|██████████| 1042/1042 [03:08<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100, loss: 0.39819, acc: 0.97708, val_loss: 3.56683, val_accuracy: 0.58290\n"
     ]
    }
   ],
   "source": [
    "min_loss = np.inf\n",
    "MODEL_NAME = 'GoogLeNet_withAuX'\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    # Model Training\n",
    "    # 훈련 손실과 정확도를 반환 받습니다.\n",
    "    train_loss, train_acc = model_train_withAux(ex_model_1, train_loader, criterion_1, optimizer_1, device)\n",
    "\n",
    "    # 검증 손실과 검증 정확도를 반환 받습니다.\n",
    "    val_loss, val_acc = model_evaluate_withAux(ex_model_1, test_loader, criterion_1, device)   \n",
    "    \n",
    "    # val_loss 가 개선되었다면 min_loss를 갱신하고 model의 가중치(weights)를 저장합니다.\n",
    "    if val_loss < min_loss:\n",
    "        print(f'[INFO] val_loss has been improved from '\n",
    "            f'{min_loss:.5f} to {val_loss:.5f}. Saving Model!')\n",
    "        min_loss = val_loss\n",
    "        torch.save(ex_model_1.state_dict(), f'{MODEL_NAME}.pth')\n",
    "    \n",
    "    # Epoch 별 결과를 출력합니다.\n",
    "    print(f'epoch {epoch+1:02d}, loss: {train_loss:.5f}, acc: {train_acc:.5f}, '\n",
    "        f'val_loss: {val_loss:.5f}, val_accuracy: {val_acc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation loss: 1.63855, evaluation accuracy: 0.56660\n"
     ]
    }
   ],
   "source": [
    "ex_model_1.load_state_dict(torch.load(f'{MODEL_NAME}.pth'))\n",
    "\n",
    "final_loss, final_acc = model_evaluate(ex_model_1, test_loader, criterion_1, device)\n",
    "print(f'evaluation loss: {final_loss:.5f}, evaluation accuracy: {final_acc:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
